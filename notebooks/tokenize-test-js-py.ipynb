{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipelines\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datasets\n",
    "from transformers import RobertaTokenizer,RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_split_data(language):\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset('code_search_net', language, split=['train', 'validation', 'test'], trust_remote_code=True)\n",
    "\n",
    "    # Combine train and validation datasets\n",
    "    combined_train = concatenate_datasets([dataset[0], dataset[1]])\n",
    "\n",
    "    # Split the combined dataset into 75% training and 25% testing\n",
    "    train_test_split = combined_train.train_test_split(test_size=0.25, seed=42)\n",
    "    train_dataset = train_test_split['train']\n",
    "    test_dataset = train_test_split['test']\n",
    "\n",
    "    # Split the training dataset into 90% training and 10% validation\n",
    "    train_validation_split = train_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "    train_dataset = train_validation_split['train']\n",
    "    validation_dataset = train_validation_split['test']\n",
    "    \n",
    "    return train_dataset, validation_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the datasets return tensorflow tensors\n",
    "def preprocess_tokenizeation(dataset):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "    def preprocess_function(inputs):\n",
    "        code_strings = inputs['func_code_string']\n",
    "        return tokenizer(code_strings,truncation = True,  padding='max_length', max_length=512, return_tensors=\"tf\")\n",
    "    tokenized_data = dataset.map(preprocess_function,batched=True)\n",
    "\n",
    "    \n",
    "    return tokenized_data\n",
    "\n",
    "#function converts tokenized data to a tf dataset for performance\n",
    "def to_tf(tokenized_data, batch_size=16):\n",
    "    # Define the columns to use\n",
    "    columns = [\"input_ids\", \"attention_mask\"]\n",
    "    if \"label\" in tokenized_data.column_names:\n",
    "        columns.append(\"label\")\n",
    "\n",
    "    # Print columns to debug\n",
    "    print(f\"Columns in dataset: {tokenized_data.column_names}\")\n",
    "    print(f\"Columns to use: {columns}\")\n",
    "\n",
    "    # Print the first few examples to debug\n",
    "    for i, example in enumerate(tokenized_data):\n",
    "        if i < 5:  # Limit to the first 5 examples\n",
    "            print(f\"Example {i}: {example}\")\n",
    "\n",
    "    # Define a collate function that handles the possible absence of 'label'\n",
    "    def collate_fn(features):\n",
    "        collated = {}\n",
    "        for column in columns:\n",
    "            if column in features[0]:\n",
    "                collated[column] = [feature[column] for feature in features]\n",
    "            else:\n",
    "                if column == \"label\":\n",
    "                    collated[column] = [None] * len(features)\n",
    "                else:\n",
    "                    raise ValueError(f\"Missing column {column} in example {features[0]}\")\n",
    "        return collated\n",
    "\n",
    "    # Convert the dataset to TensorFlow format\n",
    "    return tokenized_data.to_tf_dataset(\n",
    "        columns=columns,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls the above functions for the python and js datasets and then tokenizes them and converts them to tensorflow datasets\n",
    "python_train, python_validation,python_test = load_and_split_data(\"python\")\n",
    "js_dataset = load_and_split_data('javascript')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'repository_name': 'gwastro/pycbc', 'func_path_in_repository': 'pycbc/types/frequencyseries.py', 'func_name': 'FrequencySeries.match', 'whole_func_string': 'def match(self, other, psd=None,\\n              low_frequency_cutoff=None, high_frequency_cutoff=None):\\n        \"\"\" Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.\\n        \"\"\"\\n        from pycbc.types import TimeSeries\\n        from pycbc.filter import match\\n\\n        if isinstance(other, TimeSeries):\\n            if other.duration != self.duration:\\n                other = other.copy()\\n                other.resize(int(other.sample_rate * self.duration))\\n\\n            other = other.to_frequencyseries()\\n        \\n        if len(other) != len(self):\\n            other = other.copy()\\n            other.resize(len(self))\\n\\n        if psd is not None and len(psd) > len(self):\\n            psd = psd.copy()\\n            psd.resize(len(self))\\n\\n        return match(self, other, psd=psd,\\n                     low_frequency_cutoff=low_frequency_cutoff,\\n                     high_frequency_cutoff=high_frequency_cutoff)', 'language': 'python', 'func_code_string': 'def match(self, other, psd=None,\\n              low_frequency_cutoff=None, high_frequency_cutoff=None):\\n        \"\"\" Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.\\n        \"\"\"\\n        from pycbc.types import TimeSeries\\n        from pycbc.filter import match\\n\\n        if isinstance(other, TimeSeries):\\n            if other.duration != self.duration:\\n                other = other.copy()\\n                other.resize(int(other.sample_rate * self.duration))\\n\\n            other = other.to_frequencyseries()\\n        \\n        if len(other) != len(self):\\n            other = other.copy()\\n            other.resize(len(self))\\n\\n        if psd is not None and len(psd) > len(self):\\n            psd = psd.copy()\\n            psd.resize(len(self))\\n\\n        return match(self, other, psd=psd,\\n                     low_frequency_cutoff=low_frequency_cutoff,\\n                     high_frequency_cutoff=high_frequency_cutoff)', 'func_code_tokens': ['def', 'match', '(', 'self', ',', 'other', ',', 'psd', '=', 'None', ',', 'low_frequency_cutoff', '=', 'None', ',', 'high_frequency_cutoff', '=', 'None', ')', ':', 'from', 'pycbc', '.', 'types', 'import', 'TimeSeries', 'from', 'pycbc', '.', 'filter', 'import', 'match', 'if', 'isinstance', '(', 'other', ',', 'TimeSeries', ')', ':', 'if', 'other', '.', 'duration', '!=', 'self', '.', 'duration', ':', 'other', '=', 'other', '.', 'copy', '(', ')', 'other', '.', 'resize', '(', 'int', '(', 'other', '.', 'sample_rate', '*', 'self', '.', 'duration', ')', ')', 'other', '=', 'other', '.', 'to_frequencyseries', '(', ')', 'if', 'len', '(', 'other', ')', '!=', 'len', '(', 'self', ')', ':', 'other', '=', 'other', '.', 'copy', '(', ')', 'other', '.', 'resize', '(', 'len', '(', 'self', ')', ')', 'if', 'psd', 'is', 'not', 'None', 'and', 'len', '(', 'psd', ')', '>', 'len', '(', 'self', ')', ':', 'psd', '=', 'psd', '.', 'copy', '(', ')', 'psd', '.', 'resize', '(', 'len', '(', 'self', ')', ')', 'return', 'match', '(', 'self', ',', 'other', ',', 'psd', '=', 'psd', ',', 'low_frequency_cutoff', '=', 'low_frequency_cutoff', ',', 'high_frequency_cutoff', '=', 'high_frequency_cutoff', ')'], 'func_documentation_string': 'Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.', 'func_documentation_tokens': ['Return', 'the', 'match', 'between', 'the', 'two', 'TimeSeries', 'or', 'FrequencySeries', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/gwastro/pycbc/blob/7a64cdd104d263f1b6ea0b01e6841837d05a4cb3/pycbc/types/frequencyseries.py#L502-L550'}\n",
      " {'repository_name': 'juicer/juicer', 'func_path_in_repository': 'juicer/utils/__init__.py', 'func_name': 'return_hdr', 'whole_func_string': 'def return_hdr(ts, package):\\n    \"\"\"\\n    Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py\\n    \"\"\"\\n    try:\\n        fdno = os.open(package, os.O_RDONLY)\\n    except OSError:\\n        hdr = None\\n        return hdr\\n    ts.setVSFlags(~(rpm.RPMVSF_NOMD5 | rpm.RPMVSF_NEEDPAYLOAD))\\n    try:\\n        hdr = ts.hdrFromFdno(fdno)\\n    except rpm.error:\\n        hdr = None\\n        raise rpm.error\\n    if type(hdr) != rpm.hdr:\\n        hdr = None\\n    ts.setVSFlags(0)\\n    os.close(fdno)\\n    return hdr', 'language': 'python', 'func_code_string': 'def return_hdr(ts, package):\\n    \"\"\"\\n    Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py\\n    \"\"\"\\n    try:\\n        fdno = os.open(package, os.O_RDONLY)\\n    except OSError:\\n        hdr = None\\n        return hdr\\n    ts.setVSFlags(~(rpm.RPMVSF_NOMD5 | rpm.RPMVSF_NEEDPAYLOAD))\\n    try:\\n        hdr = ts.hdrFromFdno(fdno)\\n    except rpm.error:\\n        hdr = None\\n        raise rpm.error\\n    if type(hdr) != rpm.hdr:\\n        hdr = None\\n    ts.setVSFlags(0)\\n    os.close(fdno)\\n    return hdr', 'func_code_tokens': ['def', 'return_hdr', '(', 'ts', ',', 'package', ')', ':', 'try', ':', 'fdno', '=', 'os', '.', 'open', '(', 'package', ',', 'os', '.', 'O_RDONLY', ')', 'except', 'OSError', ':', 'hdr', '=', 'None', 'return', 'hdr', 'ts', '.', 'setVSFlags', '(', '~', '(', 'rpm', '.', 'RPMVSF_NOMD5', '|', 'rpm', '.', 'RPMVSF_NEEDPAYLOAD', ')', ')', 'try', ':', 'hdr', '=', 'ts', '.', 'hdrFromFdno', '(', 'fdno', ')', 'except', 'rpm', '.', 'error', ':', 'hdr', '=', 'None', 'raise', 'rpm', '.', 'error', 'if', 'type', '(', 'hdr', ')', '!=', 'rpm', '.', 'hdr', ':', 'hdr', '=', 'None', 'ts', '.', 'setVSFlags', '(', '0', ')', 'os', '.', 'close', '(', 'fdno', ')', 'return', 'hdr'], 'func_documentation_string': 'Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py', 'func_documentation_tokens': ['Hand', 'back', 'the', 'hdr', '-', 'duh', '-', 'if', 'the', 'pkg', 'is', 'foobar', 'handback', 'None'], 'split_name': 'train', 'func_code_url': 'https://github.com/juicer/juicer/blob/0c9f0fd59e293d45df6b46e81f675d33221c600d/juicer/utils/__init__.py#L482-L504'}\n",
      " {'repository_name': 'DLR-RM/RAFCON', 'func_path_in_repository': 'source/rafcon/gui/controllers/state_machine_tree.py', 'func_name': 'StateMachineTreeController.redo_expansion_state', 'whole_func_string': 'def redo_expansion_state(self, ignore_not_existing_rows=False):\\n        \"\"\" Considers the tree to be collapsed and expand into all tree item with the flag set True \"\"\"\\n\\n        def set_expansion_state(state_path):\\n            state_row_iter = self.state_row_iter_dict_by_state_path[state_path]\\n            if state_row_iter:  # may elements are missing afterwards\\n                state_row_path = self.tree_store.get_path(state_row_iter)\\n                self.view.expand_to_path(state_row_path)\\n\\n        if self.__my_selected_sm_id is not None and self.__my_selected_sm_id in self.__expansion_state:\\n            expansion_state = self.__expansion_state[self.__my_selected_sm_id]\\n            try:\\n                for state_path, state_row_expanded in expansion_state.items():\\n                    if state_path in self.state_row_iter_dict_by_state_path:\\n                        if state_row_expanded:\\n                            set_expansion_state(state_path)\\n                    else:\\n                        if not ignore_not_existing_rows and self._selected_sm_model and \\\\\\n                                self._selected_sm_model.state_machine.get_state_by_path(state_path, as_check=True):\\n                            state = self._selected_sm_model.state_machine.get_state_by_path(state_path)\\n                            if isinstance(state, LibraryState) or state.is_root_state_of_library or \\\\\\n                                    state.get_next_upper_library_root_state():\\n                                continue\\n                            logger.error(\"State not in StateMachineTree but in StateMachine, {0}.\".format(state_path))\\n\\n            except (TypeError, KeyError):\\n                logger.error(\"Expansion state of state machine {0} could not be restored\"\\n                             \"\".format(self.__my_selected_sm_id))', 'language': 'python', 'func_code_string': 'def redo_expansion_state(self, ignore_not_existing_rows=False):\\n        \"\"\" Considers the tree to be collapsed and expand into all tree item with the flag set True \"\"\"\\n\\n        def set_expansion_state(state_path):\\n            state_row_iter = self.state_row_iter_dict_by_state_path[state_path]\\n            if state_row_iter:  # may elements are missing afterwards\\n                state_row_path = self.tree_store.get_path(state_row_iter)\\n                self.view.expand_to_path(state_row_path)\\n\\n        if self.__my_selected_sm_id is not None and self.__my_selected_sm_id in self.__expansion_state:\\n            expansion_state = self.__expansion_state[self.__my_selected_sm_id]\\n            try:\\n                for state_path, state_row_expanded in expansion_state.items():\\n                    if state_path in self.state_row_iter_dict_by_state_path:\\n                        if state_row_expanded:\\n                            set_expansion_state(state_path)\\n                    else:\\n                        if not ignore_not_existing_rows and self._selected_sm_model and \\\\\\n                                self._selected_sm_model.state_machine.get_state_by_path(state_path, as_check=True):\\n                            state = self._selected_sm_model.state_machine.get_state_by_path(state_path)\\n                            if isinstance(state, LibraryState) or state.is_root_state_of_library or \\\\\\n                                    state.get_next_upper_library_root_state():\\n                                continue\\n                            logger.error(\"State not in StateMachineTree but in StateMachine, {0}.\".format(state_path))\\n\\n            except (TypeError, KeyError):\\n                logger.error(\"Expansion state of state machine {0} could not be restored\"\\n                             \"\".format(self.__my_selected_sm_id))', 'func_code_tokens': ['def', 'redo_expansion_state', '(', 'self', ',', 'ignore_not_existing_rows', '=', 'False', ')', ':', 'def', 'set_expansion_state', '(', 'state_path', ')', ':', 'state_row_iter', '=', 'self', '.', 'state_row_iter_dict_by_state_path', '[', 'state_path', ']', 'if', 'state_row_iter', ':', '# may elements are missing afterwards', 'state_row_path', '=', 'self', '.', 'tree_store', '.', 'get_path', '(', 'state_row_iter', ')', 'self', '.', 'view', '.', 'expand_to_path', '(', 'state_row_path', ')', 'if', 'self', '.', '__my_selected_sm_id', 'is', 'not', 'None', 'and', 'self', '.', '__my_selected_sm_id', 'in', 'self', '.', '__expansion_state', ':', 'expansion_state', '=', 'self', '.', '__expansion_state', '[', 'self', '.', '__my_selected_sm_id', ']', 'try', ':', 'for', 'state_path', ',', 'state_row_expanded', 'in', 'expansion_state', '.', 'items', '(', ')', ':', 'if', 'state_path', 'in', 'self', '.', 'state_row_iter_dict_by_state_path', ':', 'if', 'state_row_expanded', ':', 'set_expansion_state', '(', 'state_path', ')', 'else', ':', 'if', 'not', 'ignore_not_existing_rows', 'and', 'self', '.', '_selected_sm_model', 'and', 'self', '.', '_selected_sm_model', '.', 'state_machine', '.', 'get_state_by_path', '(', 'state_path', ',', 'as_check', '=', 'True', ')', ':', 'state', '=', 'self', '.', '_selected_sm_model', '.', 'state_machine', '.', 'get_state_by_path', '(', 'state_path', ')', 'if', 'isinstance', '(', 'state', ',', 'LibraryState', ')', 'or', 'state', '.', 'is_root_state_of_library', 'or', 'state', '.', 'get_next_upper_library_root_state', '(', ')', ':', 'continue', 'logger', '.', 'error', '(', '\"State not in StateMachineTree but in StateMachine, {0}.\"', '.', 'format', '(', 'state_path', ')', ')', 'except', '(', 'TypeError', ',', 'KeyError', ')', ':', 'logger', '.', 'error', '(', '\"Expansion state of state machine {0} could not be restored\"', '\"\"', '.', 'format', '(', 'self', '.', '__my_selected_sm_id', ')', ')'], 'func_documentation_string': 'Considers the tree to be collapsed and expand into all tree item with the flag set True', 'func_documentation_tokens': ['Considers', 'the', 'tree', 'to', 'be', 'collapsed', 'and', 'expand', 'into', 'all', 'tree', 'item', 'with', 'the', 'flag', 'set', 'True'], 'split_name': 'train', 'func_code_url': 'https://github.com/DLR-RM/RAFCON/blob/24942ef1a904531f49ab8830a1dbb604441be498/source/rafcon/gui/controllers/state_machine_tree.py#L271-L298'}\n",
      " ...\n",
      " {'repository_name': 'OSSOS/MOP', 'func_path_in_repository': 'src/jjk/preproc/MOPfits_old.py', 'func_name': 'stack', 'whole_func_string': 'def stack(outfile,infiles,verbose=0):\\n    \"\"\"\\n    Stick infiles into outfiles as FITS extensions.\\n\\n    outfile willl contain an MEF format file of the single extension FITS\\n    files named in the infiles array\\n    \"\"\"\\n    \\n    import os, sys, string, tempfile, shutil\\n    import pyfits, re, time\\n\\n### if there is a pre-existing MEF file for output then append to it\\n### otherwise we need to create a PrimaryHDU\\n    if os.access(outfile,os.R_OK)!=1:\\n        if verbose:\\n            print \"Creating new MEF file: \",outfile\\n        outfile=create_mef(outfile)\\n        \\n### get a handle for the output image, _open is the local variant of\\n### pyfits.open and just does some error recovery if pyfits.open raises an\\n### exception.\\n    out = pyfits.open(outfile,\\'append\\')\\n    hdr = out[0].header\\n    count=0\\n\\n### append the fits files given on the command line to the\\n### output file.\\n    det_xmin=None\\n    det_xmax=None\\n    det_ymin=None\\n    det_ymax=None\\n    for infile in infiles:\\n        if verbose:\\n            print \"Adding \",infile,\" to \",outfile\\n\\n        ### _open  tries to handle bad fits format exceptions.\\n        file=_open(infile)\\n        if not file:\\n            raise IOError(\"Cann\\'t get the HDU for \"+infile)\\n\\n        for hdu in file:\\n            extname=None\\n            if hdu.header.has_key(\\'EXTNAME\\') :\\n                extname=hdu.header[\\'EXTNAME\\']\\n            elif hdu.header.has_key(\\'EXTVER\\') :\\n                extname=\"ccd\"+string.zfill(hdu.header.has_key(\\'EXTVER\\'),2)\\n                    \\n            if hdu.header.has_key(\\'EPOCH\\'):\\n                if hdu.header.has_key(\\'EQUINOX\\'):\\n                    del hdu.header[\\'EPOCH\\']\\n                else:\\n                    hdu.header.update(\\'EQUINOX\\',hdu.header[\\'EQUINOX\\'].value,\\n                                      comment=hdu.header[\\'EQUINOX\\'].comment)\\n\\n            ahdu=pyfits.ImageHDU(data=hdu.data, header=hdu.header, name=extname)\\n            out.append(ahdu)\\n\\n        ### build the size of the overall detector\\n            if hdu.header.has_key(\\'DETSEC\\'):\\n                values=re.findall(r\\'(\\\\d+)\\',\\n                                  hdu.header[\\'DETSEC\\'])\\n                if len(values)==4:\\n                    xmin=int(values[0])\\n                    xmax=int(values[1])\\n                    ymin=int(values[2])\\n                    ymax=int(values[3])\\n\\n                if xmin>xmax:\\n                    t=xmin\\n                    xmin=xmax\\n                    xmax=t\\n                if ymin>ymax:\\n                    t=ymin\\n                    ymin=ymax\\n                    ymax=t\\n\\n                if xmin<det_xmin or not det_xmin:\\n                    det_xmin=xmin\\n                if xmax>det_xmax or not det_xmax:\\n                    det_xmax=xmax\\n                if ymin<det_ymin or not det_ymin:\\n                    det_ymin=ymin\\n                if ymax>det_ymax or not det_ymax:\\n                    det_ymax=ymax\\n    \\n\\n        file.close()\\n\\n\\n    detsize=\\'[\\'+str(det_xmin)+\\':\\'+str(det_xmax)+\\',\\'+str(det_ymin)+\\':\\'+str(det_ymax)+\\']\\'\\n    out[0].header.update(\\'DETSIZE\\',detsize,comment=\\'Size of Mosaic\\')\\n    out.close()    \\n    if verbose:\\n        print \"Done building MEF: \",outfile\\n    return 0', 'language': 'python', 'func_code_string': 'def stack(outfile,infiles,verbose=0):\\n    \"\"\"\\n    Stick infiles into outfiles as FITS extensions.\\n\\n    outfile willl contain an MEF format file of the single extension FITS\\n    files named in the infiles array\\n    \"\"\"\\n    \\n    import os, sys, string, tempfile, shutil\\n    import pyfits, re, time\\n\\n### if there is a pre-existing MEF file for output then append to it\\n### otherwise we need to create a PrimaryHDU\\n    if os.access(outfile,os.R_OK)!=1:\\n        if verbose:\\n            print \"Creating new MEF file: \",outfile\\n        outfile=create_mef(outfile)\\n        \\n### get a handle for the output image, _open is the local variant of\\n### pyfits.open and just does some error recovery if pyfits.open raises an\\n### exception.\\n    out = pyfits.open(outfile,\\'append\\')\\n    hdr = out[0].header\\n    count=0\\n\\n### append the fits files given on the command line to the\\n### output file.\\n    det_xmin=None\\n    det_xmax=None\\n    det_ymin=None\\n    det_ymax=None\\n    for infile in infiles:\\n        if verbose:\\n            print \"Adding \",infile,\" to \",outfile\\n\\n        ### _open  tries to handle bad fits format exceptions.\\n        file=_open(infile)\\n        if not file:\\n            raise IOError(\"Cann\\'t get the HDU for \"+infile)\\n\\n        for hdu in file:\\n            extname=None\\n            if hdu.header.has_key(\\'EXTNAME\\') :\\n                extname=hdu.header[\\'EXTNAME\\']\\n            elif hdu.header.has_key(\\'EXTVER\\') :\\n                extname=\"ccd\"+string.zfill(hdu.header.has_key(\\'EXTVER\\'),2)\\n                    \\n            if hdu.header.has_key(\\'EPOCH\\'):\\n                if hdu.header.has_key(\\'EQUINOX\\'):\\n                    del hdu.header[\\'EPOCH\\']\\n                else:\\n                    hdu.header.update(\\'EQUINOX\\',hdu.header[\\'EQUINOX\\'].value,\\n                                      comment=hdu.header[\\'EQUINOX\\'].comment)\\n\\n            ahdu=pyfits.ImageHDU(data=hdu.data, header=hdu.header, name=extname)\\n            out.append(ahdu)\\n\\n        ### build the size of the overall detector\\n            if hdu.header.has_key(\\'DETSEC\\'):\\n                values=re.findall(r\\'(\\\\d+)\\',\\n                                  hdu.header[\\'DETSEC\\'])\\n                if len(values)==4:\\n                    xmin=int(values[0])\\n                    xmax=int(values[1])\\n                    ymin=int(values[2])\\n                    ymax=int(values[3])\\n\\n                if xmin>xmax:\\n                    t=xmin\\n                    xmin=xmax\\n                    xmax=t\\n                if ymin>ymax:\\n                    t=ymin\\n                    ymin=ymax\\n                    ymax=t\\n\\n                if xmin<det_xmin or not det_xmin:\\n                    det_xmin=xmin\\n                if xmax>det_xmax or not det_xmax:\\n                    det_xmax=xmax\\n                if ymin<det_ymin or not det_ymin:\\n                    det_ymin=ymin\\n                if ymax>det_ymax or not det_ymax:\\n                    det_ymax=ymax\\n    \\n\\n        file.close()\\n\\n\\n    detsize=\\'[\\'+str(det_xmin)+\\':\\'+str(det_xmax)+\\',\\'+str(det_ymin)+\\':\\'+str(det_ymax)+\\']\\'\\n    out[0].header.update(\\'DETSIZE\\',detsize,comment=\\'Size of Mosaic\\')\\n    out.close()    \\n    if verbose:\\n        print \"Done building MEF: \",outfile\\n    return 0', 'func_code_tokens': ['def', 'stack', '(', 'outfile', ',', 'infiles', ',', 'verbose', '=', '0', ')', ':', 'import', 'os', ',', 'sys', ',', 'string', ',', 'tempfile', ',', 'shutil', 'import', 'pyfits', ',', 're', ',', 'time', '### if there is a pre-existing MEF file for output then append to it', '### otherwise we need to create a PrimaryHDU', 'if', 'os', '.', 'access', '(', 'outfile', ',', 'os', '.', 'R_OK', ')', '!=', '1', ':', 'if', 'verbose', ':', 'print', '\"Creating new MEF file: \"', ',', 'outfile', 'outfile', '=', 'create_mef', '(', 'outfile', ')', '### get a handle for the output image, _open is the local variant of', '### pyfits.open and just does some error recovery if pyfits.open raises an', '### exception.', 'out', '=', 'pyfits', '.', 'open', '(', 'outfile', ',', \"'append'\", ')', 'hdr', '=', 'out', '[', '0', ']', '.', 'header', 'count', '=', '0', '### append the fits files given on the command line to the', '### output file.', 'det_xmin', '=', 'None', 'det_xmax', '=', 'None', 'det_ymin', '=', 'None', 'det_ymax', '=', 'None', 'for', 'infile', 'in', 'infiles', ':', 'if', 'verbose', ':', 'print', '\"Adding \"', ',', 'infile', ',', '\" to \"', ',', 'outfile', '### _open  tries to handle bad fits format exceptions.', 'file', '=', '_open', '(', 'infile', ')', 'if', 'not', 'file', ':', 'raise', 'IOError', '(', '\"Cann\\'t get the HDU for \"', '+', 'infile', ')', 'for', 'hdu', 'in', 'file', ':', 'extname', '=', 'None', 'if', 'hdu', '.', 'header', '.', 'has_key', '(', \"'EXTNAME'\", ')', ':', 'extname', '=', 'hdu', '.', 'header', '[', \"'EXTNAME'\", ']', 'elif', 'hdu', '.', 'header', '.', 'has_key', '(', \"'EXTVER'\", ')', ':', 'extname', '=', '\"ccd\"', '+', 'string', '.', 'zfill', '(', 'hdu', '.', 'header', '.', 'has_key', '(', \"'EXTVER'\", ')', ',', '2', ')', 'if', 'hdu', '.', 'header', '.', 'has_key', '(', \"'EPOCH'\", ')', ':', 'if', 'hdu', '.', 'header', '.', 'has_key', '(', \"'EQUINOX'\", ')', ':', 'del', 'hdu', '.', 'header', '[', \"'EPOCH'\", ']', 'else', ':', 'hdu', '.', 'header', '.', 'update', '(', \"'EQUINOX'\", ',', 'hdu', '.', 'header', '[', \"'EQUINOX'\", ']', '.', 'value', ',', 'comment', '=', 'hdu', '.', 'header', '[', \"'EQUINOX'\", ']', '.', 'comment', ')', 'ahdu', '=', 'pyfits', '.', 'ImageHDU', '(', 'data', '=', 'hdu', '.', 'data', ',', 'header', '=', 'hdu', '.', 'header', ',', 'name', '=', 'extname', ')', 'out', '.', 'append', '(', 'ahdu', ')', '### build the size of the overall detector', 'if', 'hdu', '.', 'header', '.', 'has_key', '(', \"'DETSEC'\", ')', ':', 'values', '=', 're', '.', 'findall', '(', \"r'(\\\\d+)'\", ',', 'hdu', '.', 'header', '[', \"'DETSEC'\", ']', ')', 'if', 'len', '(', 'values', ')', '==', '4', ':', 'xmin', '=', 'int', '(', 'values', '[', '0', ']', ')', 'xmax', '=', 'int', '(', 'values', '[', '1', ']', ')', 'ymin', '=', 'int', '(', 'values', '[', '2', ']', ')', 'ymax', '=', 'int', '(', 'values', '[', '3', ']', ')', 'if', 'xmin', '>', 'xmax', ':', 't', '=', 'xmin', 'xmin', '=', 'xmax', 'xmax', '=', 't', 'if', 'ymin', '>', 'ymax', ':', 't', '=', 'ymin', 'ymin', '=', 'ymax', 'ymax', '=', 't', 'if', 'xmin', '<', 'det_xmin', 'or', 'not', 'det_xmin', ':', 'det_xmin', '=', 'xmin', 'if', 'xmax', '>', 'det_xmax', 'or', 'not', 'det_xmax', ':', 'det_xmax', '=', 'xmax', 'if', 'ymin', '<', 'det_ymin', 'or', 'not', 'det_ymin', ':', 'det_ymin', '=', 'ymin', 'if', 'ymax', '>', 'det_ymax', 'or', 'not', 'det_ymax', ':', 'det_ymax', '=', 'ymax', 'file', '.', 'close', '(', ')', 'detsize', '=', \"'['\", '+', 'str', '(', 'det_xmin', ')', '+', \"':'\", '+', 'str', '(', 'det_xmax', ')', '+', \"','\", '+', 'str', '(', 'det_ymin', ')', '+', \"':'\", '+', 'str', '(', 'det_ymax', ')', '+', \"']'\", 'out', '[', '0', ']', '.', 'header', '.', 'update', '(', \"'DETSIZE'\", ',', 'detsize', ',', 'comment', '=', \"'Size of Mosaic'\", ')', 'out', '.', 'close', '(', ')', 'if', 'verbose', ':', 'print', '\"Done building MEF: \"', ',', 'outfile', 'return', '0'], 'func_documentation_string': 'Stick infiles into outfiles as FITS extensions.\\n\\n    outfile willl contain an MEF format file of the single extension FITS\\n    files named in the infiles array', 'func_documentation_tokens': ['Stick', 'infiles', 'into', 'outfiles', 'as', 'FITS', 'extensions', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/OSSOS/MOP/blob/94f91d32ad5ec081d5a1ebd67604a838003465af/src/jjk/preproc/MOPfits_old.py#L380-L474'}\n",
      " {'repository_name': 'vertexproject/synapse', 'func_path_in_repository': 'synapse/lib/cache.py', 'func_name': 'LruDict.get', 'whole_func_string': \"def get(self, key, default=None):\\n        '''\\n        Note:  we override default impl from parent to avoid costly KeyError\\n        '''\\n        valu = self.data.get(key, default)\\n        if key in self.data:\\n            self.data.move_to_end(key)\\n        return valu\", 'language': 'python', 'func_code_string': \"def get(self, key, default=None):\\n        '''\\n        Note:  we override default impl from parent to avoid costly KeyError\\n        '''\\n        valu = self.data.get(key, default)\\n        if key in self.data:\\n            self.data.move_to_end(key)\\n        return valu\", 'func_code_tokens': ['def', 'get', '(', 'self', ',', 'key', ',', 'default', '=', 'None', ')', ':', 'valu', '=', 'self', '.', 'data', '.', 'get', '(', 'key', ',', 'default', ')', 'if', 'key', 'in', 'self', '.', 'data', ':', 'self', '.', 'data', '.', 'move_to_end', '(', 'key', ')', 'return', 'valu'], 'func_documentation_string': 'Note:  we override default impl from parent to avoid costly KeyError', 'func_documentation_tokens': ['Note', ':', 'we', 'override', 'default', 'impl', 'from', 'parent', 'to', 'avoid', 'costly', 'KeyError'], 'split_name': 'train', 'func_code_url': 'https://github.com/vertexproject/synapse/blob/22e67c5a8f6d7caddbcf34b39ab1bd2d6c4a6e0b/synapse/lib/cache.py#L101-L108'}\n",
      " {'repository_name': 'tanghaibao/jcvi', 'func_path_in_repository': 'jcvi/annotation/depth.py', 'func_name': 'query', 'whole_func_string': 'def query(args):\\n    \"\"\"\\n    %prog query binfile fastafile ctgID baseID\\n\\n    Get the depth at a particular base.\\n    \"\"\"\\n    p = OptionParser(query.__doc__)\\n    opts, args = p.parse_args(args)\\n\\n    if len(args) != 4:\\n        sys.exit(not p.print_help())\\n\\n    binfile, fastafile, ctgID, baseID = args\\n    b = BinFile(binfile, fastafile)\\n    ar = b.mmarray\\n\\n    fastasize, sizes, offsets = get_offsets(fastafile)\\n    oi = offsets[ctgID] + int(baseID) - 1\\n    print(\"\\\\t\".join((ctgID, baseID, str(ar[oi]))))', 'language': 'python', 'func_code_string': 'def query(args):\\n    \"\"\"\\n    %prog query binfile fastafile ctgID baseID\\n\\n    Get the depth at a particular base.\\n    \"\"\"\\n    p = OptionParser(query.__doc__)\\n    opts, args = p.parse_args(args)\\n\\n    if len(args) != 4:\\n        sys.exit(not p.print_help())\\n\\n    binfile, fastafile, ctgID, baseID = args\\n    b = BinFile(binfile, fastafile)\\n    ar = b.mmarray\\n\\n    fastasize, sizes, offsets = get_offsets(fastafile)\\n    oi = offsets[ctgID] + int(baseID) - 1\\n    print(\"\\\\t\".join((ctgID, baseID, str(ar[oi]))))', 'func_code_tokens': ['def', 'query', '(', 'args', ')', ':', 'p', '=', 'OptionParser', '(', 'query', '.', '__doc__', ')', 'opts', ',', 'args', '=', 'p', '.', 'parse_args', '(', 'args', ')', 'if', 'len', '(', 'args', ')', '!=', '4', ':', 'sys', '.', 'exit', '(', 'not', 'p', '.', 'print_help', '(', ')', ')', 'binfile', ',', 'fastafile', ',', 'ctgID', ',', 'baseID', '=', 'args', 'b', '=', 'BinFile', '(', 'binfile', ',', 'fastafile', ')', 'ar', '=', 'b', '.', 'mmarray', 'fastasize', ',', 'sizes', ',', 'offsets', '=', 'get_offsets', '(', 'fastafile', ')', 'oi', '=', 'offsets', '[', 'ctgID', ']', '+', 'int', '(', 'baseID', ')', '-', '1', 'print', '(', '\"\\\\t\"', '.', 'join', '(', '(', 'ctgID', ',', 'baseID', ',', 'str', '(', 'ar', '[', 'oi', ']', ')', ')', ')', ')'], 'func_documentation_string': '%prog query binfile fastafile ctgID baseID\\n\\n    Get the depth at a particular base.', 'func_documentation_tokens': ['%prog', 'query', 'binfile', 'fastafile', 'ctgID', 'baseID'], 'split_name': 'train', 'func_code_url': 'https://github.com/tanghaibao/jcvi/blob/d2e31a77b6ade7f41f3b321febc2b4744d1cdeca/jcvi/annotation/depth.py#L144-L162'}]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(python_train))\n",
    "#remove all comments from the code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'repository_name': 'gwastro/pycbc', 'func_pat...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def remove_comments(code):\n",
    "    # Remove single-line comments (e.g., // in JavaScript or # in Python)\n",
    "    code = re.sub(r'#.*', '', code)\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    # Remove multi-line comments (e.g., /* */ in JavaScript)\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_train_tok = preprocess_tokenizeation(python_train)\n",
    "python_valid_tok = preprocess_tokenizeation(python_validation)\n",
    "python_test_tok = preprocess_tokenizeation(python_test)\n",
    "#js_dataset_tokenized = preprocess_tokenizeation(js_dataset)\n",
    "\n",
    "\n",
    "#js_Dset_tok_tf = to_tf(js_dataset_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'input_ids', 'attention_mask']\n",
      "Columns to use: ['input_ids', 'attention_mask']\n",
      "Example 0: {'repository_name': 'gwastro/pycbc', 'func_path_in_repository': 'pycbc/types/frequencyseries.py', 'func_name': 'FrequencySeries.match', 'whole_func_string': 'def match(self, other, psd=None,\\n              low_frequency_cutoff=None, high_frequency_cutoff=None):\\n        \"\"\" Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.\\n        \"\"\"\\n        from pycbc.types import TimeSeries\\n        from pycbc.filter import match\\n\\n        if isinstance(other, TimeSeries):\\n            if other.duration != self.duration:\\n                other = other.copy()\\n                other.resize(int(other.sample_rate * self.duration))\\n\\n            other = other.to_frequencyseries()\\n        \\n        if len(other) != len(self):\\n            other = other.copy()\\n            other.resize(len(self))\\n\\n        if psd is not None and len(psd) > len(self):\\n            psd = psd.copy()\\n            psd.resize(len(self))\\n\\n        return match(self, other, psd=psd,\\n                     low_frequency_cutoff=low_frequency_cutoff,\\n                     high_frequency_cutoff=high_frequency_cutoff)', 'language': 'python', 'func_code_string': 'def match(self, other, psd=None,\\n              low_frequency_cutoff=None, high_frequency_cutoff=None):\\n        \"\"\" Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.\\n        \"\"\"\\n        from pycbc.types import TimeSeries\\n        from pycbc.filter import match\\n\\n        if isinstance(other, TimeSeries):\\n            if other.duration != self.duration:\\n                other = other.copy()\\n                other.resize(int(other.sample_rate * self.duration))\\n\\n            other = other.to_frequencyseries()\\n        \\n        if len(other) != len(self):\\n            other = other.copy()\\n            other.resize(len(self))\\n\\n        if psd is not None and len(psd) > len(self):\\n            psd = psd.copy()\\n            psd.resize(len(self))\\n\\n        return match(self, other, psd=psd,\\n                     low_frequency_cutoff=low_frequency_cutoff,\\n                     high_frequency_cutoff=high_frequency_cutoff)', 'func_code_tokens': ['def', 'match', '(', 'self', ',', 'other', ',', 'psd', '=', 'None', ',', 'low_frequency_cutoff', '=', 'None', ',', 'high_frequency_cutoff', '=', 'None', ')', ':', 'from', 'pycbc', '.', 'types', 'import', 'TimeSeries', 'from', 'pycbc', '.', 'filter', 'import', 'match', 'if', 'isinstance', '(', 'other', ',', 'TimeSeries', ')', ':', 'if', 'other', '.', 'duration', '!=', 'self', '.', 'duration', ':', 'other', '=', 'other', '.', 'copy', '(', ')', 'other', '.', 'resize', '(', 'int', '(', 'other', '.', 'sample_rate', '*', 'self', '.', 'duration', ')', ')', 'other', '=', 'other', '.', 'to_frequencyseries', '(', ')', 'if', 'len', '(', 'other', ')', '!=', 'len', '(', 'self', ')', ':', 'other', '=', 'other', '.', 'copy', '(', ')', 'other', '.', 'resize', '(', 'len', '(', 'self', ')', ')', 'if', 'psd', 'is', 'not', 'None', 'and', 'len', '(', 'psd', ')', '>', 'len', '(', 'self', ')', ':', 'psd', '=', 'psd', '.', 'copy', '(', ')', 'psd', '.', 'resize', '(', 'len', '(', 'self', ')', ')', 'return', 'match', '(', 'self', ',', 'other', ',', 'psd', '=', 'psd', ',', 'low_frequency_cutoff', '=', 'low_frequency_cutoff', ',', 'high_frequency_cutoff', '=', 'high_frequency_cutoff', ')'], 'func_documentation_string': 'Return the match between the two TimeSeries or FrequencySeries.\\n\\n        Return the match between two waveforms. This is equivelant to the overlap\\n        maximized over time and phase. By default, the other vector will be\\n        resized to match self. Beware, this may remove high frequency content or the\\n        end of the vector.\\n\\n        Parameters\\n        ----------\\n        other : TimeSeries or FrequencySeries\\n            The input vector containing a waveform.\\n        psd : Frequency Series\\n            A power spectral density to weight the overlap.\\n        low_frequency_cutoff : {None, float}, optional\\n            The frequency to begin the match.\\n        high_frequency_cutoff : {None, float}, optional\\n            The frequency to stop the match.\\n        index: int\\n            The number of samples to shift to get the match.\\n\\n        Returns\\n        -------\\n        match: float\\n        index: int\\n            The number of samples to shift to get the match.', 'func_documentation_tokens': ['Return', 'the', 'match', 'between', 'the', 'two', 'TimeSeries', 'or', 'FrequencySeries', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/gwastro/pycbc/blob/7a64cdd104d263f1b6ea0b01e6841837d05a4cb3/pycbc/types/frequencyseries.py#L502-L550', 'input_ids': [0, 9232, 914, 1640, 13367, 6, 97, 6, 181, 28045, 5214, 29802, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 614, 1215, 36274, 1215, 8267, 1529, 5214, 29802, 6, 239, 1215, 36274, 1215, 8267, 1529, 5214, 29802, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 11968, 5, 914, 227, 5, 80, 3421, 25166, 50, 42389, 25166, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 11968, 5, 914, 227, 80, 4605, 33334, 4, 152, 16, 4065, 2088, 462, 927, 7, 5, 27573, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 21056, 1538, 81, 86, 8, 4359, 4, 870, 6814, 6, 5, 97, 37681, 40, 28, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 5032, 1538, 7, 914, 1403, 4, 41926, 6, 42, 189, 3438, 239, 13135, 1383, 50, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 253, 9, 5, 37681, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 47930, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 45177, 5579, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 97, 4832, 3421, 25166, 50, 42389, 25166, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 20, 8135, 37681, 8200, 10, 4605, 3899, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 181, 28045, 4832, 42389, 3265, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 83, 476, 45113, 16522, 7, 2408, 5, 27573, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 614, 1215, 36274, 1215, 8267, 1529, 4832, 25522, 29802, 6, 15754, 48268, 17679, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 20, 13135, 7, 1642, 5, 914, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 239, 1215, 36274, 1215, 8267, 1529, 4832, 25522, 29802, 6, 15754, 48268, 17679, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 20, 13135, 7, 912, 5, 914, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1965, 35, 6979, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 20, 346, 9, 7931, 7, 3294, 7, 120, 5, 914, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 29974, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 48364, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 914, 35, 15754, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1965, 35, 6979, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 20, 346, 9, 7931, 7, 3294, 7, 120, 5, 914, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 31, 19290, 438, 23219, 4, 41817, 6595, 3421, 25166, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 31, 19290, 438, 23219, 4, 46617, 6595, 914, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 16, 48768, 1640, 7443, 6, 3421, 25166, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 97, 4, 41218, 49333, 1403, 4, 41218, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Example 1: {'repository_name': 'juicer/juicer', 'func_path_in_repository': 'juicer/utils/__init__.py', 'func_name': 'return_hdr', 'whole_func_string': 'def return_hdr(ts, package):\\n    \"\"\"\\n    Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py\\n    \"\"\"\\n    try:\\n        fdno = os.open(package, os.O_RDONLY)\\n    except OSError:\\n        hdr = None\\n        return hdr\\n    ts.setVSFlags(~(rpm.RPMVSF_NOMD5 | rpm.RPMVSF_NEEDPAYLOAD))\\n    try:\\n        hdr = ts.hdrFromFdno(fdno)\\n    except rpm.error:\\n        hdr = None\\n        raise rpm.error\\n    if type(hdr) != rpm.hdr:\\n        hdr = None\\n    ts.setVSFlags(0)\\n    os.close(fdno)\\n    return hdr', 'language': 'python', 'func_code_string': 'def return_hdr(ts, package):\\n    \"\"\"\\n    Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py\\n    \"\"\"\\n    try:\\n        fdno = os.open(package, os.O_RDONLY)\\n    except OSError:\\n        hdr = None\\n        return hdr\\n    ts.setVSFlags(~(rpm.RPMVSF_NOMD5 | rpm.RPMVSF_NEEDPAYLOAD))\\n    try:\\n        hdr = ts.hdrFromFdno(fdno)\\n    except rpm.error:\\n        hdr = None\\n        raise rpm.error\\n    if type(hdr) != rpm.hdr:\\n        hdr = None\\n    ts.setVSFlags(0)\\n    os.close(fdno)\\n    return hdr', 'func_code_tokens': ['def', 'return_hdr', '(', 'ts', ',', 'package', ')', ':', 'try', ':', 'fdno', '=', 'os', '.', 'open', '(', 'package', ',', 'os', '.', 'O_RDONLY', ')', 'except', 'OSError', ':', 'hdr', '=', 'None', 'return', 'hdr', 'ts', '.', 'setVSFlags', '(', '~', '(', 'rpm', '.', 'RPMVSF_NOMD5', '|', 'rpm', '.', 'RPMVSF_NEEDPAYLOAD', ')', ')', 'try', ':', 'hdr', '=', 'ts', '.', 'hdrFromFdno', '(', 'fdno', ')', 'except', 'rpm', '.', 'error', ':', 'hdr', '=', 'None', 'raise', 'rpm', '.', 'error', 'if', 'type', '(', 'hdr', ')', '!=', 'rpm', '.', 'hdr', ':', 'hdr', '=', 'None', 'ts', '.', 'setVSFlags', '(', '0', ')', 'os', '.', 'close', '(', 'fdno', ')', 'return', 'hdr'], 'func_documentation_string': 'Hand back the hdr - duh - if the pkg is foobar handback None\\n\\n    Shamelessly stolen from Seth Vidal\\n    http://yum.baseurl.org/download/misc/checksig.py', 'func_documentation_tokens': ['Hand', 'back', 'the', 'hdr', '-', 'duh', '-', 'if', 'the', 'pkg', 'is', 'foobar', 'handback', 'None'], 'split_name': 'train', 'func_code_url': 'https://github.com/juicer/juicer/blob/0c9f0fd59e293d45df6b46e81f675d33221c600d/juicer/utils/__init__.py#L482-L504', 'input_ids': [0, 9232, 671, 1215, 298, 10232, 1640, 1872, 6, 3737, 3256, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 7406, 124, 5, 1368, 10232, 111, 4279, 298, 111, 114, 5, 181, 9043, 16, 9565, 22468, 865, 1644, 9291, 50140, 1437, 1437, 1437, 17917, 13802, 352, 3579, 31, 10747, 468, 11934, 50118, 1437, 1437, 1437, 2054, 640, 219, 783, 4, 11070, 6423, 4, 1957, 73, 41536, 73, 45321, 73, 28511, 1023, 4, 17163, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 860, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 856, 417, 2362, 5457, 11988, 4, 12592, 1640, 46181, 6, 11988, 4, 673, 1215, 34158, 2191, 14079, 43, 50118, 1437, 1437, 1437, 4682, 384, 3388, 338, 21929, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1368, 10232, 5457, 9291, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 1368, 10232, 50118, 1437, 1437, 1437, 42270, 4, 8738, 11859, 48167, 1640, 34437, 1640, 43773, 4, 500, 5683, 11859, 597, 1215, 487, 3765, 495, 245, 1721, 36461, 4, 500, 5683, 11859, 597, 1215, 9009, 1691, 3439, 975, 27822, 35122, 50118, 1437, 1437, 1437, 860, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1368, 10232, 5457, 42270, 4, 298, 10232, 7605, 597, 417, 2362, 1640, 37379, 2362, 43, 50118, 1437, 1437, 1437, 4682, 36461, 4, 44223, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1368, 10232, 5457, 9291, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1693, 36461, 4, 44223, 50118, 1437, 1437, 1437, 114, 1907, 1640, 298, 10232, 43, 49333, 36461, 4, 298, 10232, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1368, 10232, 5457, 9291, 50118, 1437, 1437, 1437, 42270, 4, 8738, 11859, 48167, 1640, 288, 43, 50118, 1437, 1437, 1437, 11988, 4, 22641, 1640, 37379, 2362, 43, 50118, 1437, 1437, 1437, 671, 1368, 10232, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 2: {'repository_name': 'DLR-RM/RAFCON', 'func_path_in_repository': 'source/rafcon/gui/controllers/state_machine_tree.py', 'func_name': 'StateMachineTreeController.redo_expansion_state', 'whole_func_string': 'def redo_expansion_state(self, ignore_not_existing_rows=False):\\n        \"\"\" Considers the tree to be collapsed and expand into all tree item with the flag set True \"\"\"\\n\\n        def set_expansion_state(state_path):\\n            state_row_iter = self.state_row_iter_dict_by_state_path[state_path]\\n            if state_row_iter:  # may elements are missing afterwards\\n                state_row_path = self.tree_store.get_path(state_row_iter)\\n                self.view.expand_to_path(state_row_path)\\n\\n        if self.__my_selected_sm_id is not None and self.__my_selected_sm_id in self.__expansion_state:\\n            expansion_state = self.__expansion_state[self.__my_selected_sm_id]\\n            try:\\n                for state_path, state_row_expanded in expansion_state.items():\\n                    if state_path in self.state_row_iter_dict_by_state_path:\\n                        if state_row_expanded:\\n                            set_expansion_state(state_path)\\n                    else:\\n                        if not ignore_not_existing_rows and self._selected_sm_model and \\\\\\n                                self._selected_sm_model.state_machine.get_state_by_path(state_path, as_check=True):\\n                            state = self._selected_sm_model.state_machine.get_state_by_path(state_path)\\n                            if isinstance(state, LibraryState) or state.is_root_state_of_library or \\\\\\n                                    state.get_next_upper_library_root_state():\\n                                continue\\n                            logger.error(\"State not in StateMachineTree but in StateMachine, {0}.\".format(state_path))\\n\\n            except (TypeError, KeyError):\\n                logger.error(\"Expansion state of state machine {0} could not be restored\"\\n                             \"\".format(self.__my_selected_sm_id))', 'language': 'python', 'func_code_string': 'def redo_expansion_state(self, ignore_not_existing_rows=False):\\n        \"\"\" Considers the tree to be collapsed and expand into all tree item with the flag set True \"\"\"\\n\\n        def set_expansion_state(state_path):\\n            state_row_iter = self.state_row_iter_dict_by_state_path[state_path]\\n            if state_row_iter:  # may elements are missing afterwards\\n                state_row_path = self.tree_store.get_path(state_row_iter)\\n                self.view.expand_to_path(state_row_path)\\n\\n        if self.__my_selected_sm_id is not None and self.__my_selected_sm_id in self.__expansion_state:\\n            expansion_state = self.__expansion_state[self.__my_selected_sm_id]\\n            try:\\n                for state_path, state_row_expanded in expansion_state.items():\\n                    if state_path in self.state_row_iter_dict_by_state_path:\\n                        if state_row_expanded:\\n                            set_expansion_state(state_path)\\n                    else:\\n                        if not ignore_not_existing_rows and self._selected_sm_model and \\\\\\n                                self._selected_sm_model.state_machine.get_state_by_path(state_path, as_check=True):\\n                            state = self._selected_sm_model.state_machine.get_state_by_path(state_path)\\n                            if isinstance(state, LibraryState) or state.is_root_state_of_library or \\\\\\n                                    state.get_next_upper_library_root_state():\\n                                continue\\n                            logger.error(\"State not in StateMachineTree but in StateMachine, {0}.\".format(state_path))\\n\\n            except (TypeError, KeyError):\\n                logger.error(\"Expansion state of state machine {0} could not be restored\"\\n                             \"\".format(self.__my_selected_sm_id))', 'func_code_tokens': ['def', 'redo_expansion_state', '(', 'self', ',', 'ignore_not_existing_rows', '=', 'False', ')', ':', 'def', 'set_expansion_state', '(', 'state_path', ')', ':', 'state_row_iter', '=', 'self', '.', 'state_row_iter_dict_by_state_path', '[', 'state_path', ']', 'if', 'state_row_iter', ':', '# may elements are missing afterwards', 'state_row_path', '=', 'self', '.', 'tree_store', '.', 'get_path', '(', 'state_row_iter', ')', 'self', '.', 'view', '.', 'expand_to_path', '(', 'state_row_path', ')', 'if', 'self', '.', '__my_selected_sm_id', 'is', 'not', 'None', 'and', 'self', '.', '__my_selected_sm_id', 'in', 'self', '.', '__expansion_state', ':', 'expansion_state', '=', 'self', '.', '__expansion_state', '[', 'self', '.', '__my_selected_sm_id', ']', 'try', ':', 'for', 'state_path', ',', 'state_row_expanded', 'in', 'expansion_state', '.', 'items', '(', ')', ':', 'if', 'state_path', 'in', 'self', '.', 'state_row_iter_dict_by_state_path', ':', 'if', 'state_row_expanded', ':', 'set_expansion_state', '(', 'state_path', ')', 'else', ':', 'if', 'not', 'ignore_not_existing_rows', 'and', 'self', '.', '_selected_sm_model', 'and', 'self', '.', '_selected_sm_model', '.', 'state_machine', '.', 'get_state_by_path', '(', 'state_path', ',', 'as_check', '=', 'True', ')', ':', 'state', '=', 'self', '.', '_selected_sm_model', '.', 'state_machine', '.', 'get_state_by_path', '(', 'state_path', ')', 'if', 'isinstance', '(', 'state', ',', 'LibraryState', ')', 'or', 'state', '.', 'is_root_state_of_library', 'or', 'state', '.', 'get_next_upper_library_root_state', '(', ')', ':', 'continue', 'logger', '.', 'error', '(', '\"State not in StateMachineTree but in StateMachine, {0}.\"', '.', 'format', '(', 'state_path', ')', ')', 'except', '(', 'TypeError', ',', 'KeyError', ')', ':', 'logger', '.', 'error', '(', '\"Expansion state of state machine {0} could not be restored\"', '\"\"', '.', 'format', '(', 'self', '.', '__my_selected_sm_id', ')', ')'], 'func_documentation_string': 'Considers the tree to be collapsed and expand into all tree item with the flag set True', 'func_documentation_tokens': ['Considers', 'the', 'tree', 'to', 'be', 'collapsed', 'and', 'expand', 'into', 'all', 'tree', 'item', 'with', 'the', 'flag', 'set', 'True'], 'split_name': 'train', 'func_code_url': 'https://github.com/DLR-RM/RAFCON/blob/24942ef1a904531f49ab8830a1dbb604441be498/source/rafcon/gui/controllers/state_machine_tree.py#L271-L298', 'input_ids': [0, 9232, 1275, 139, 1215, 18793, 40787, 1215, 4897, 1640, 13367, 6, 8861, 1215, 3654, 1215, 19865, 1215, 13415, 5214, 46659, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 9051, 8936, 5, 3907, 7, 28, 7793, 8, 3003, 88, 70, 3907, 6880, 19, 5, 3794, 278, 7447, 49434, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 3816, 278, 1215, 18793, 40787, 1215, 4897, 1640, 4897, 1215, 22609, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 194, 1215, 4610, 1215, 8660, 5457, 1403, 4, 4897, 1215, 4610, 1215, 8660, 1215, 25867, 1215, 1409, 1215, 4897, 1215, 22609, 10975, 4897, 1215, 22609, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 194, 1215, 4610, 1215, 8660, 35, 1437, 849, 189, 4785, 32, 1716, 11795, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 194, 1215, 4610, 1215, 22609, 5457, 1403, 4, 21512, 1215, 8005, 4, 6460, 1215, 22609, 1640, 4897, 1215, 4610, 1215, 8660, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 5877, 4, 18793, 463, 1215, 560, 1215, 22609, 1640, 4897, 1215, 4610, 1215, 22609, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 1403, 4, 30529, 4783, 1215, 41642, 1215, 9426, 1215, 808, 16, 45, 9291, 8, 1403, 4, 30529, 4783, 1215, 41642, 1215, 9426, 1215, 808, 11, 1403, 4, 30529, 18793, 40787, 1215, 4897, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2919, 1215, 4897, 5457, 1403, 4, 30529, 18793, 40787, 1215, 4897, 10975, 13367, 4, 30529, 4783, 1215, 41642, 1215, 9426, 1215, 808, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 860, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13, 194, 1215, 22609, 6, 194, 1215, 4610, 1215, 18793, 13833, 11, 2919, 1215, 4897, 4, 46740, 49536, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 194, 1215, 22609, 11, 1403, 4, 4897, 1215, 4610, 1215, 8660, 1215, 25867, 1215, 1409, 1215, 4897, 1215, 22609, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 194, 1215, 4610, 1215, 18793, 13833, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 278, 1215, 18793, 40787, 1215, 4897, 1640, 4897, 1215, 22609, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1493, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 45, 8861, 1215, 3654, 1215, 19865, 1215, 13415, 8, 1403, 48030, 41642, 1215, 9426, 1215, 21818, 8, 44128, 50118, 1437, 1437, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Example 3: {'repository_name': 'svenevs/exhale', 'func_path_in_repository': 'exhale/graph.py', 'func_name': 'ExhaleRoot.gerrymanderNodeFilenames', 'whole_func_string': 'def gerrymanderNodeFilenames(self):\\n        \\'\\'\\'\\n        When creating nodes, the filename needs to be relative to ``conf.py``, so it\\n        will include ``self.root_directory``.  However, when generating the API, the\\n        file we are writing to is in the same directory as the generated node files so\\n        we need to remove the directory path from a given ExhaleNode\\'s ``file_name``\\n        before we can ``include`` it or use it in a ``toctree``.\\n        \\'\\'\\'\\n        for node in self.all_nodes:\\n            node.file_name = os.path.basename(node.file_name)\\n            if node.kind == \"file\":\\n                node.program_file = os.path.basename(node.program_file)', 'language': 'python', 'func_code_string': 'def gerrymanderNodeFilenames(self):\\n        \\'\\'\\'\\n        When creating nodes, the filename needs to be relative to ``conf.py``, so it\\n        will include ``self.root_directory``.  However, when generating the API, the\\n        file we are writing to is in the same directory as the generated node files so\\n        we need to remove the directory path from a given ExhaleNode\\'s ``file_name``\\n        before we can ``include`` it or use it in a ``toctree``.\\n        \\'\\'\\'\\n        for node in self.all_nodes:\\n            node.file_name = os.path.basename(node.file_name)\\n            if node.kind == \"file\":\\n                node.program_file = os.path.basename(node.program_file)', 'func_code_tokens': ['def', 'gerrymanderNodeFilenames', '(', 'self', ')', ':', 'for', 'node', 'in', 'self', '.', 'all_nodes', ':', 'node', '.', 'file_name', '=', 'os', '.', 'path', '.', 'basename', '(', 'node', '.', 'file_name', ')', 'if', 'node', '.', 'kind', '==', '\"file\"', ':', 'node', '.', 'program_file', '=', 'os', '.', 'path', '.', 'basename', '(', 'node', '.', 'program_file', ')'], 'func_documentation_string': \"When creating nodes, the filename needs to be relative to ``conf.py``, so it\\n        will include ``self.root_directory``.  However, when generating the API, the\\n        file we are writing to is in the same directory as the generated node files so\\n        we need to remove the directory path from a given ExhaleNode's ``file_name``\\n        before we can ``include`` it or use it in a ``toctree``.\", 'func_documentation_tokens': ['When', 'creating', 'nodes', 'the', 'filename', 'needs', 'to', 'be', 'relative', 'to', 'conf', '.', 'py', 'so', 'it', 'will', 'include', 'self', '.', 'root_directory', '.', 'However', 'when', 'generating', 'the', 'API', 'the', 'file', 'we', 'are', 'writing', 'to', 'is', 'in', 'the', 'same', 'directory', 'as', 'the', 'generated', 'node', 'files', 'so', 'we', 'need', 'to', 'remove', 'the', 'directory', 'path', 'from', 'a', 'given', 'ExhaleNode', 's', 'file_name', 'before', 'we', 'can', 'include', 'it', 'or', 'use', 'it', 'in', 'a', 'toctree', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/svenevs/exhale/blob/fe7644829057af622e467bb529db6c03a830da99/exhale/graph.py#L3375-L3386', 'input_ids': [0, 9232, 821, 11228, 119, 6072, 48271, 36361, 225, 12336, 1640, 13367, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 520, 2351, 32833, 6, 5, 48786, 782, 7, 28, 5407, 7, 45518, 17075, 4, 17163, 49519, 6, 98, 24, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 40, 680, 45518, 13367, 4, 29059, 1215, 48626, 49519, 4, 1437, 635, 6, 77, 10846, 5, 21013, 6, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2870, 52, 32, 2410, 7, 16, 11, 5, 276, 31826, 25, 5, 5129, 37908, 6773, 98, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 52, 240, 7, 3438, 5, 31826, 2718, 31, 10, 576, 3015, 298, 1627, 48271, 18, 45518, 21710, 1215, 13650, 49519, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 137, 52, 64, 45518, 47209, 49519, 24, 50, 304, 24, 11, 10, 45518, 560, 3894, 5314, 49519, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13, 37908, 11, 1403, 4, 1250, 1215, 282, 19160, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 37908, 4, 21710, 1215, 13650, 5457, 11988, 4, 22609, 4, 15609, 45838, 1640, 46840, 4, 21710, 1215, 13650, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 37908, 4, 11584, 45994, 22, 21710, 7862, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 37908, 4, 28644, 1215, 21710, 5457, 11988, 4, 22609, 4, 15609, 45838, 1640, 46840, 4, 28644, 1215, 21710, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 4: {'repository_name': 'PyPSA/PyPSA', 'func_path_in_repository': 'pypsa/networkclustering.py', 'func_name': 'stubs_clustering', 'whole_func_string': 'def stubs_clustering(network,use_reduced_coordinates=True, line_length_factor=1.0):\\n    \"\"\"Cluster network by reducing stubs and stubby trees\\n    (i.e. sequentially reducing dead-ends).\\n\\n    Parameters\\n    ----------\\n    network : pypsa.Network\\n    use_reduced_coordinates : boolean\\n        If True, do not average clusters, but take from busmap.\\n    line_length_factor : float\\n        Factor to multiply the crow-flies distance between new buses in order to get new\\n        line lengths.\\n\\n    Returns\\n    -------\\n    Clustering : named tuple\\n        A named tuple containing network, busmap and linemap\\n    \"\"\"\\n\\n    busmap = busmap_by_stubs(network)\\n\\n    #reset coordinates to the new reduced guys, rather than taking an average\\n    if use_reduced_coordinates:\\n        # TODO : FIX THIS HACK THAT HAS UNEXPECTED SIDE-EFFECTS,\\n        # i.e. network is changed in place!!\\n        network.buses.loc[busmap.index,[\\'x\\',\\'y\\']] = network.buses.loc[busmap,[\\'x\\',\\'y\\']].values\\n\\n    return get_clustering_from_busmap(network, busmap, line_length_factor=line_length_factor)', 'language': 'python', 'func_code_string': 'def stubs_clustering(network,use_reduced_coordinates=True, line_length_factor=1.0):\\n    \"\"\"Cluster network by reducing stubs and stubby trees\\n    (i.e. sequentially reducing dead-ends).\\n\\n    Parameters\\n    ----------\\n    network : pypsa.Network\\n    use_reduced_coordinates : boolean\\n        If True, do not average clusters, but take from busmap.\\n    line_length_factor : float\\n        Factor to multiply the crow-flies distance between new buses in order to get new\\n        line lengths.\\n\\n    Returns\\n    -------\\n    Clustering : named tuple\\n        A named tuple containing network, busmap and linemap\\n    \"\"\"\\n\\n    busmap = busmap_by_stubs(network)\\n\\n    #reset coordinates to the new reduced guys, rather than taking an average\\n    if use_reduced_coordinates:\\n        # TODO : FIX THIS HACK THAT HAS UNEXPECTED SIDE-EFFECTS,\\n        # i.e. network is changed in place!!\\n        network.buses.loc[busmap.index,[\\'x\\',\\'y\\']] = network.buses.loc[busmap,[\\'x\\',\\'y\\']].values\\n\\n    return get_clustering_from_busmap(network, busmap, line_length_factor=line_length_factor)', 'func_code_tokens': ['def', 'stubs_clustering', '(', 'network', ',', 'use_reduced_coordinates', '=', 'True', ',', 'line_length_factor', '=', '1.0', ')', ':', 'busmap', '=', 'busmap_by_stubs', '(', 'network', ')', '#reset coordinates to the new reduced guys, rather than taking an average', 'if', 'use_reduced_coordinates', ':', '# TODO : FIX THIS HACK THAT HAS UNEXPECTED SIDE-EFFECTS,', '# i.e. network is changed in place!!', 'network', '.', 'buses', '.', 'loc', '[', 'busmap', '.', 'index', ',', '[', \"'x'\", ',', \"'y'\", ']', ']', '=', 'network', '.', 'buses', '.', 'loc', '[', 'busmap', ',', '[', \"'x'\", ',', \"'y'\", ']', ']', '.', 'values', 'return', 'get_clustering_from_busmap', '(', 'network', ',', 'busmap', ',', 'line_length_factor', '=', 'line_length_factor', ')'], 'func_documentation_string': 'Cluster network by reducing stubs and stubby trees\\n    (i.e. sequentially reducing dead-ends).\\n\\n    Parameters\\n    ----------\\n    network : pypsa.Network\\n    use_reduced_coordinates : boolean\\n        If True, do not average clusters, but take from busmap.\\n    line_length_factor : float\\n        Factor to multiply the crow-flies distance between new buses in order to get new\\n        line lengths.\\n\\n    Returns\\n    -------\\n    Clustering : named tuple\\n        A named tuple containing network, busmap and linemap', 'func_documentation_tokens': ['Cluster', 'network', 'by', 'reducing', 'stubs', 'and', 'stubby', 'trees', '(', 'i', '.', 'e', '.', 'sequentially', 'reducing', 'dead', '-', 'ends', ')', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/PyPSA/PyPSA/blob/46954b1b3c21460550f7104681517065279a53b7/pypsa/networkclustering.py#L544-L571', 'input_ids': [0, 9232, 35672, 29, 1215, 3998, 4193, 2961, 1640, 34728, 6, 3698, 1215, 2050, 33862, 1215, 39219, 34244, 5214, 36948, 6, 516, 1215, 16096, 1215, 31192, 5214, 134, 4, 288, 3256, 50118, 1437, 1437, 1437, 49434, 11428, 10504, 1546, 30, 4881, 35672, 29, 8, 35672, 1409, 3980, 50118, 1437, 1437, 1437, 36, 118, 4, 242, 4, 16721, 16722, 4881, 1462, 12, 8845, 322, 50140, 1437, 1437, 1437, 47930, 50118, 1437, 1437, 1437, 45177, 5579, 50118, 1437, 1437, 1437, 1546, 4832, 19290, 3275, 102, 4, 40283, 50118, 1437, 1437, 1437, 304, 1215, 2050, 33862, 1215, 39219, 34244, 4832, 49378, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 318, 7447, 6, 109, 45, 674, 28255, 6, 53, 185, 31, 2353, 32557, 4, 50118, 1437, 1437, 1437, 516, 1215, 16096, 1215, 31192, 4832, 15754, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 19372, 7, 37571, 5, 35946, 12, 37085, 4472, 227, 92, 8159, 11, 645, 7, 120, 92, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 516, 18915, 4, 50140, 1437, 1437, 1437, 29974, 50118, 1437, 1437, 1437, 48364, 50118, 1437, 1437, 1437, 2893, 4193, 2961, 4832, 1440, 49683, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 83, 1440, 49683, 8200, 1546, 6, 2353, 32557, 8, 43646, 1115, 50118, 1437, 1437, 1437, 49434, 50140, 1437, 1437, 1437, 2353, 32557, 5457, 2353, 32557, 1215, 1409, 1215, 620, 19424, 1640, 34728, 43, 50140, 1437, 1437, 1437, 849, 45703, 34721, 7, 5, 92, 2906, 1669, 6, 1195, 87, 602, 41, 674, 50118, 1437, 1437, 1437, 114, 304, 1215, 2050, 33862, 1215, 39219, 34244, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 41694, 673, 4832, 42344, 10652, 289, 14940, 24394, 31963, 2604, 45102, 15004, 1691, 208, 14645, 12, 28991, 3586, 2685, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 939, 4, 242, 4, 1546, 16, 1714, 11, 317, 12846, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1546, 4, 428, 9764, 4, 26516, 10975, 18924, 32557, 4, 18480, 47789, 108, 1178, 47429, 219, 108, 48392, 5457, 1546, 4, 428, 9764, 4, 26516, 10975, 18924, 32557, 47789, 108, 1178, 47429, 219, 44403, 8174, 43994, 50140, 1437, 1437, 1437, 671, 120, 1215, 3998, 4193, 2961, 1215, 7761, 1215, 18924, 32557, 1640, 34728, 6, 2353, 32557, 6, 516, 1215, 16096, 1215, 31192, 5214, 1902, 1215, 16096, 1215, 31192, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Columns in dataset: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'input_ids', 'attention_mask']\n",
      "Columns to use: ['input_ids', 'attention_mask']\n",
      "Example 0: {'repository_name': 'pywbem/pywbem', 'func_path_in_repository': 'pywbem/cim_obj.py', 'func_name': 'CIMClass.copy', 'whole_func_string': 'def copy(self):\\n        \"\"\"\\n        Return a new :class:`~pywbem.CIMClass` object that is a copy\\n        of this CIM class.\\n\\n        This is a middle-deep copy; any mutable types in attributes except the\\n        following are copied, so besides these exceptions, modifications of the\\n        original object will not affect the returned copy, and vice versa. The\\n        following mutable types are not copied and are therefore shared between\\n        original and copy:\\n\\n        * The :class:`~pywbem.CIMProperty` objects in the\\n          :attr:`~pywbem.CIMClass.properties` dictionary (but not the\\n          dictionary object itself)\\n        * The :class:`~pywbem.CIMMethod` objects in the\\n          :attr:`~pywbem.CIMClass.methods` dictionary (but not the dictionary\\n          object itself)\\n        * The :class:`~pywbem.CIMQualifier` objects in the\\n          :attr:`~pywbem.CIMClass.qualifiers` dictionary (but not the\\n          dictionary object itself)\\n\\n        Note that the Python functions :func:`py:copy.copy` and\\n        :func:`py:copy.deepcopy` can be used to create completely shallow or\\n        completely deep copies of objects of this class.\\n        \"\"\"\\n        return CIMClass(\\n            self.classname,\\n            properties=self.properties,  # setter copies\\n            methods=self.methods,  # setter copies\\n            superclass=self.superclass,\\n            qualifiers=self.qualifiers,  # setter copies\\n            path=self.path)', 'language': 'python', 'func_code_string': 'def copy(self):\\n        \"\"\"\\n        Return a new :class:`~pywbem.CIMClass` object that is a copy\\n        of this CIM class.\\n\\n        This is a middle-deep copy; any mutable types in attributes except the\\n        following are copied, so besides these exceptions, modifications of the\\n        original object will not affect the returned copy, and vice versa. The\\n        following mutable types are not copied and are therefore shared between\\n        original and copy:\\n\\n        * The :class:`~pywbem.CIMProperty` objects in the\\n          :attr:`~pywbem.CIMClass.properties` dictionary (but not the\\n          dictionary object itself)\\n        * The :class:`~pywbem.CIMMethod` objects in the\\n          :attr:`~pywbem.CIMClass.methods` dictionary (but not the dictionary\\n          object itself)\\n        * The :class:`~pywbem.CIMQualifier` objects in the\\n          :attr:`~pywbem.CIMClass.qualifiers` dictionary (but not the\\n          dictionary object itself)\\n\\n        Note that the Python functions :func:`py:copy.copy` and\\n        :func:`py:copy.deepcopy` can be used to create completely shallow or\\n        completely deep copies of objects of this class.\\n        \"\"\"\\n        return CIMClass(\\n            self.classname,\\n            properties=self.properties,  # setter copies\\n            methods=self.methods,  # setter copies\\n            superclass=self.superclass,\\n            qualifiers=self.qualifiers,  # setter copies\\n            path=self.path)', 'func_code_tokens': ['def', 'copy', '(', 'self', ')', ':', 'return', 'CIMClass', '(', 'self', '.', 'classname', ',', 'properties', '=', 'self', '.', 'properties', ',', '# setter copies', 'methods', '=', 'self', '.', 'methods', ',', '# setter copies', 'superclass', '=', 'self', '.', 'superclass', ',', 'qualifiers', '=', 'self', '.', 'qualifiers', ',', '# setter copies', 'path', '=', 'self', '.', 'path', ')'], 'func_documentation_string': 'Return a new :class:`~pywbem.CIMClass` object that is a copy\\n        of this CIM class.\\n\\n        This is a middle-deep copy; any mutable types in attributes except the\\n        following are copied, so besides these exceptions, modifications of the\\n        original object will not affect the returned copy, and vice versa. The\\n        following mutable types are not copied and are therefore shared between\\n        original and copy:\\n\\n        * The :class:`~pywbem.CIMProperty` objects in the\\n          :attr:`~pywbem.CIMClass.properties` dictionary (but not the\\n          dictionary object itself)\\n        * The :class:`~pywbem.CIMMethod` objects in the\\n          :attr:`~pywbem.CIMClass.methods` dictionary (but not the dictionary\\n          object itself)\\n        * The :class:`~pywbem.CIMQualifier` objects in the\\n          :attr:`~pywbem.CIMClass.qualifiers` dictionary (but not the\\n          dictionary object itself)\\n\\n        Note that the Python functions :func:`py:copy.copy` and\\n        :func:`py:copy.deepcopy` can be used to create completely shallow or\\n        completely deep copies of objects of this class.', 'func_documentation_tokens': ['Return', 'a', 'new', ':', 'class', ':', '~pywbem', '.', 'CIMClass', 'object', 'that', 'is', 'a', 'copy', 'of', 'this', 'CIM', 'class', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/pywbem/pywbem/blob/e54ecb82c2211e289a268567443d60fdd489f1e4/pywbem/cim_obj.py#L4151-L4182', 'input_ids': [0, 9232, 5375, 1640, 13367, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 11968, 10, 92, 4832, 4684, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 21527, 12905, 7626, 14, 16, 10, 5375, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 9, 42, 230, 3755, 1380, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 152, 16, 10, 1692, 12, 13637, 5375, 131, 143, 16119, 868, 3505, 11, 16763, 4682, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 511, 32, 15443, 6, 98, 12035, 209, 18286, 6, 24785, 9, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1461, 7626, 40, 45, 3327, 5, 1835, 5375, 6, 8, 2626, 28550, 4, 20, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 511, 16119, 868, 3505, 32, 45, 15443, 8, 32, 3891, 1373, 227, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1461, 8, 5375, 35, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1009, 20, 4832, 4684, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 44720, 12905, 8720, 11, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4832, 44156, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 21527, 4, 47276, 12905, 36451, 36, 4297, 45, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 36451, 7626, 1495, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1009, 20, 4832, 4684, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 47967, 12905, 8720, 11, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4832, 44156, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 21527, 4, 45416, 29, 12905, 36451, 36, 4297, 45, 5, 36451, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 7626, 1495, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1009, 20, 4832, 4684, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 42170, 24072, 12905, 8720, 11, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4832, 44156, 35, 12905, 34437, 17163, 41161, 991, 4, 347, 3755, 21527, 4, 27702, 27368, 12905, 36451, 36, 4297, 45, 5, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 36451, 7626, 1495, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6068, 14, 5, 31886, 8047, 4832, 48901, 35, 12905, 17163, 35, 44273, 4, 44273, 12905, 8, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4832, 48901, 35, 12905, 17163, 35, 44273, 4, 13637, 44273, 12905, 64, 28, 341, 7, 1045, 2198, 16762, 50, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2198, 1844, 11288, 9, 8720, 9, 42, 1380, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 230, 3755, 21527, 1640, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 4684, 13650, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 3611, 5214, 13367, 4, 47276, 6, 1437, 849, 278, 1334, 11288, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Example 1: {'repository_name': 'jmvrbanac/Specter', 'func_path_in_repository': 'specter/expect.py', 'func_name': 'ExpectAssert.serialize', 'whole_func_string': 'def serialize(self):\\n        \"\"\"Serializes the ExpectAssert object for collection.\\n\\n        Warning, this will only grab the available information.\\n        It is strongly that you only call this once all specs and\\n        tests have completed.\\n        \"\"\"\\n        converted_dict = {\\n            \\'success\\': self.success,\\n            \\'assertion\\': str(self),\\n            \\'required\\': self.required\\n        }\\n        return converted_dict', 'language': 'python', 'func_code_string': 'def serialize(self):\\n        \"\"\"Serializes the ExpectAssert object for collection.\\n\\n        Warning, this will only grab the available information.\\n        It is strongly that you only call this once all specs and\\n        tests have completed.\\n        \"\"\"\\n        converted_dict = {\\n            \\'success\\': self.success,\\n            \\'assertion\\': str(self),\\n            \\'required\\': self.required\\n        }\\n        return converted_dict', 'func_code_tokens': ['def', 'serialize', '(', 'self', ')', ':', 'converted_dict', '=', '{', \"'success'\", ':', 'self', '.', 'success', ',', \"'assertion'\", ':', 'str', '(', 'self', ')', ',', \"'required'\", ':', 'self', '.', 'required', '}', 'return', 'converted_dict'], 'func_documentation_string': 'Serializes the ExpectAssert object for collection.\\n\\n        Warning, this will only grab the available information.\\n        It is strongly that you only call this once all specs and\\n        tests have completed.', 'func_documentation_tokens': ['Serializes', 'the', 'ExpectAssert', 'object', 'for', 'collection', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/jmvrbanac/Specter/blob/1f5a729b0aa16242add8c1c754efa268335e3944/specter/expect.py#L41-L53', 'input_ids': [0, 9232, 13603, 2072, 1640, 13367, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 47070, 7396, 5, 12809, 26039, 2399, 7626, 13, 2783, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 21505, 6, 42, 40, 129, 6895, 5, 577, 335, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 85, 16, 5025, 14, 47, 129, 486, 42, 683, 70, 21634, 8, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 3457, 33, 2121, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 8417, 1215, 25867, 5457, 25522, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 42776, 13373, 1403, 4, 42776, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 46346, 1499, 13373, 7031, 1640, 13367, 238, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 44240, 13373, 1403, 4, 44240, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 35524, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 8417, 1215, 25867, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 2: {'repository_name': 'joequant/cryptoexchange', 'func_path_in_repository': 'cryptoexchange/bitmex_ws.py', 'func_name': 'BitMEXWebsocket.get_ticker', 'whole_func_string': 'def get_ticker(self):\\n        \\'\\'\\'Return a ticker object. Generated from quote and trade.\\'\\'\\'\\n        lastQuote = self.data[\\'quote\\'][-1]\\n        lastTrade = self.data[\\'trade\\'][-1]\\n        ticker = {\\n            \"last\": lastTrade[\\'price\\'],\\n            \"buy\": lastQuote[\\'bidPrice\\'],\\n            \"sell\": lastQuote[\\'askPrice\\'],\\n            \"mid\": (float(lastQuote[\\'bidPrice\\'] or 0) + float(lastQuote[\\'askPrice\\'] or 0)) / 2\\n        }\\n\\n        # The instrument has a tickSize. Use it to round values.\\n        instrument = self.data[\\'instrument\\'][0]\\n        return {k: round(float(v or 0), instrument[\\'tickLog\\']) for k, v in list(ticker.items())}', 'language': 'python', 'func_code_string': 'def get_ticker(self):\\n        \\'\\'\\'Return a ticker object. Generated from quote and trade.\\'\\'\\'\\n        lastQuote = self.data[\\'quote\\'][-1]\\n        lastTrade = self.data[\\'trade\\'][-1]\\n        ticker = {\\n            \"last\": lastTrade[\\'price\\'],\\n            \"buy\": lastQuote[\\'bidPrice\\'],\\n            \"sell\": lastQuote[\\'askPrice\\'],\\n            \"mid\": (float(lastQuote[\\'bidPrice\\'] or 0) + float(lastQuote[\\'askPrice\\'] or 0)) / 2\\n        }\\n\\n        # The instrument has a tickSize. Use it to round values.\\n        instrument = self.data[\\'instrument\\'][0]\\n        return {k: round(float(v or 0), instrument[\\'tickLog\\']) for k, v in list(ticker.items())}', 'func_code_tokens': ['def', 'get_ticker', '(', 'self', ')', ':', 'lastQuote', '=', 'self', '.', 'data', '[', \"'quote'\", ']', '[', '-', '1', ']', 'lastTrade', '=', 'self', '.', 'data', '[', \"'trade'\", ']', '[', '-', '1', ']', 'ticker', '=', '{', '\"last\"', ':', 'lastTrade', '[', \"'price'\", ']', ',', '\"buy\"', ':', 'lastQuote', '[', \"'bidPrice'\", ']', ',', '\"sell\"', ':', 'lastQuote', '[', \"'askPrice'\", ']', ',', '\"mid\"', ':', '(', 'float', '(', 'lastQuote', '[', \"'bidPrice'\", ']', 'or', '0', ')', '+', 'float', '(', 'lastQuote', '[', \"'askPrice'\", ']', 'or', '0', ')', ')', '/', '2', '}', '# The instrument has a tickSize. Use it to round values.', 'instrument', '=', 'self', '.', 'data', '[', \"'instrument'\", ']', '[', '0', ']', 'return', '{', 'k', ':', 'round', '(', 'float', '(', 'v', 'or', '0', ')', ',', 'instrument', '[', \"'tickLog'\", ']', ')', 'for', 'k', ',', 'v', 'in', 'list', '(', 'ticker', '.', 'items', '(', ')', ')', '}'], 'func_documentation_string': 'Return a ticker object. Generated from quote and trade.', 'func_documentation_tokens': ['Return', 'a', 'ticker', 'object', '.', 'Generated', 'from', 'quote', 'and', 'trade', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/joequant/cryptoexchange/blob/6690fbd9a2ba00e40d7484425808c84d44233f0c/cryptoexchange/bitmex_ws.py#L92-L105', 'input_ids': [0, 9232, 120, 1215, 90, 13917, 1640, 13367, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 42555, 10, 10457, 254, 7626, 4, 15745, 1070, 31, 9740, 8, 721, 955, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 94, 48065, 5457, 1403, 4, 23687, 48759, 43948, 108, 46386, 12, 134, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 94, 35996, 5457, 1403, 4, 23687, 48759, 18582, 108, 46386, 12, 134, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 10457, 254, 5457, 25522, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22, 13751, 7862, 94, 35996, 48759, 17212, 108, 7479, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22, 3746, 7862, 94, 48065, 48759, 27607, 36677, 108, 7479, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22, 5727, 7862, 94, 48065, 48759, 4970, 36677, 108, 7479, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22, 16079, 7862, 36, 46349, 1640, 13751, 48065, 48759, 27607, 36677, 44403, 50, 321, 43, 2055, 15754, 1640, 13751, 48065, 48759, 4970, 36677, 44403, 50, 321, 35122, 1589, 132, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 35524, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 20, 10320, 34, 10, 10457, 45698, 4, 7627, 24, 7, 1062, 3266, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 10320, 5457, 1403, 4, 23687, 48759, 179, 41392, 108, 46386, 288, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 25522, 330, 35, 1062, 1640, 46349, 1640, 705, 50, 321, 238, 10320, 48759, 41791, 23345, 108, 45587, 13, 449, 6, 748, 11, 889, 1640, 90, 13917, 4, 46740, 49338, 24303, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 3: {'repository_name': 'gem/oq-engine', 'func_path_in_repository': 'openquake/hmtk/faults/fault_models.py', 'func_name': 'mtkActiveFault.generate_fault_source_model', 'whole_func_string': \"def generate_fault_source_model(self):\\n        '''\\n        Creates a resulting `openquake.hmtk` fault source set.\\n\\n        :returns:\\n            source_model - list of instances of either the :class:\\n            `openquake.hmtk.sources.simple_fault_source.mtkSimpleFaultSource`\\n            or :class:\\n            `openquake.hmtk.sources.complex_fault_source.mtkComplexFaultSource`\\n            model_weight - Corresponding weights for each source model\\n        '''\\n        source_model = []\\n        model_weight = []\\n        for iloc in range(0, self.get_number_mfd_models()):\\n            model_mfd = EvenlyDiscretizedMFD(\\n                self.mfd[0][iloc].min_mag,\\n                self.mfd[0][iloc].bin_width,\\n                self.mfd[0][iloc].occur_rates.tolist())\\n\\n            if isinstance(self.geometry, ComplexFaultGeometry):\\n                # Complex fault class\\n                source = mtkComplexFaultSource(\\n                    self.id,\\n                    self.name,\\n                    self.trt,\\n                    self.geometry.surface,\\n                    self.mfd[2][iloc],\\n                    self.rupt_aspect_ratio,\\n                    model_mfd,\\n                    self.rake)\\n                source.fault_edges = self.geometry.trace\\n            else:\\n                # Simple Fault source\\n                source = mtkSimpleFaultSource(\\n                    self.id,\\n                    self.name,\\n                    self.trt,\\n                    self.geometry.surface,\\n                    self.geometry.dip,\\n                    self.geometry.upper_depth,\\n                    self.geometry.lower_depth,\\n                    self.mfd[2][iloc],\\n                    self.rupt_aspect_ratio,\\n                    model_mfd,\\n                    self.rake)\\n                source.fault_trace = self.geometry.trace\\n            source_model.append(source)\\n            model_weight.append(self.mfd[1][iloc])\\n        return source_model, model_weight\", 'language': 'python', 'func_code_string': \"def generate_fault_source_model(self):\\n        '''\\n        Creates a resulting `openquake.hmtk` fault source set.\\n\\n        :returns:\\n            source_model - list of instances of either the :class:\\n            `openquake.hmtk.sources.simple_fault_source.mtkSimpleFaultSource`\\n            or :class:\\n            `openquake.hmtk.sources.complex_fault_source.mtkComplexFaultSource`\\n            model_weight - Corresponding weights for each source model\\n        '''\\n        source_model = []\\n        model_weight = []\\n        for iloc in range(0, self.get_number_mfd_models()):\\n            model_mfd = EvenlyDiscretizedMFD(\\n                self.mfd[0][iloc].min_mag,\\n                self.mfd[0][iloc].bin_width,\\n                self.mfd[0][iloc].occur_rates.tolist())\\n\\n            if isinstance(self.geometry, ComplexFaultGeometry):\\n                # Complex fault class\\n                source = mtkComplexFaultSource(\\n                    self.id,\\n                    self.name,\\n                    self.trt,\\n                    self.geometry.surface,\\n                    self.mfd[2][iloc],\\n                    self.rupt_aspect_ratio,\\n                    model_mfd,\\n                    self.rake)\\n                source.fault_edges = self.geometry.trace\\n            else:\\n                # Simple Fault source\\n                source = mtkSimpleFaultSource(\\n                    self.id,\\n                    self.name,\\n                    self.trt,\\n                    self.geometry.surface,\\n                    self.geometry.dip,\\n                    self.geometry.upper_depth,\\n                    self.geometry.lower_depth,\\n                    self.mfd[2][iloc],\\n                    self.rupt_aspect_ratio,\\n                    model_mfd,\\n                    self.rake)\\n                source.fault_trace = self.geometry.trace\\n            source_model.append(source)\\n            model_weight.append(self.mfd[1][iloc])\\n        return source_model, model_weight\", 'func_code_tokens': ['def', 'generate_fault_source_model', '(', 'self', ')', ':', 'source_model', '=', '[', ']', 'model_weight', '=', '[', ']', 'for', 'iloc', 'in', 'range', '(', '0', ',', 'self', '.', 'get_number_mfd_models', '(', ')', ')', ':', 'model_mfd', '=', 'EvenlyDiscretizedMFD', '(', 'self', '.', 'mfd', '[', '0', ']', '[', 'iloc', ']', '.', 'min_mag', ',', 'self', '.', 'mfd', '[', '0', ']', '[', 'iloc', ']', '.', 'bin_width', ',', 'self', '.', 'mfd', '[', '0', ']', '[', 'iloc', ']', '.', 'occur_rates', '.', 'tolist', '(', ')', ')', 'if', 'isinstance', '(', 'self', '.', 'geometry', ',', 'ComplexFaultGeometry', ')', ':', '# Complex fault class', 'source', '=', 'mtkComplexFaultSource', '(', 'self', '.', 'id', ',', 'self', '.', 'name', ',', 'self', '.', 'trt', ',', 'self', '.', 'geometry', '.', 'surface', ',', 'self', '.', 'mfd', '[', '2', ']', '[', 'iloc', ']', ',', 'self', '.', 'rupt_aspect_ratio', ',', 'model_mfd', ',', 'self', '.', 'rake', ')', 'source', '.', 'fault_edges', '=', 'self', '.', 'geometry', '.', 'trace', 'else', ':', '# Simple Fault source', 'source', '=', 'mtkSimpleFaultSource', '(', 'self', '.', 'id', ',', 'self', '.', 'name', ',', 'self', '.', 'trt', ',', 'self', '.', 'geometry', '.', 'surface', ',', 'self', '.', 'geometry', '.', 'dip', ',', 'self', '.', 'geometry', '.', 'upper_depth', ',', 'self', '.', 'geometry', '.', 'lower_depth', ',', 'self', '.', 'mfd', '[', '2', ']', '[', 'iloc', ']', ',', 'self', '.', 'rupt_aspect_ratio', ',', 'model_mfd', ',', 'self', '.', 'rake', ')', 'source', '.', 'fault_trace', '=', 'self', '.', 'geometry', '.', 'trace', 'source_model', '.', 'append', '(', 'source', ')', 'model_weight', '.', 'append', '(', 'self', '.', 'mfd', '[', '1', ']', '[', 'iloc', ']', ')', 'return', 'source_model', ',', 'model_weight'], 'func_documentation_string': 'Creates a resulting `openquake.hmtk` fault source set.\\n\\n        :returns:\\n            source_model - list of instances of either the :class:\\n            `openquake.hmtk.sources.simple_fault_source.mtkSimpleFaultSource`\\n            or :class:\\n            `openquake.hmtk.sources.complex_fault_source.mtkComplexFaultSource`\\n            model_weight - Corresponding weights for each source model', 'func_documentation_tokens': ['Creates', 'a', 'resulting', 'openquake', '.', 'hmtk', 'fault', 'source', 'set', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/gem/oq-engine/blob/8294553a0b8aba33fd96437a35065d03547d0040/openquake/hmtk/faults/fault_models.py#L509-L557', 'input_ids': [0, 9232, 5368, 1215, 506, 8839, 1215, 17747, 1215, 21818, 1640, 13367, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 27962, 293, 10, 5203, 22209, 12592, 2253, 5113, 4, 298, 16100, 330, 12905, 7684, 1300, 278, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4832, 30921, 29, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1300, 1215, 21818, 111, 889, 9, 10960, 9, 1169, 5, 4832, 4684, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22209, 12592, 2253, 5113, 4, 298, 16100, 330, 4, 29, 39412, 4, 41918, 1215, 506, 8839, 1215, 17747, 4, 16100, 330, 45093, 597, 8839, 7061, 12905, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 50, 4832, 4684, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 22209, 12592, 2253, 5113, 4, 298, 16100, 330, 4, 29, 39412, 4, 42290, 1215, 506, 8839, 1215, 17747, 4, 16100, 330, 14721, 26028, 597, 8839, 7061, 12905, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1421, 1215, 4301, 111, 24388, 154, 23341, 13, 349, 1300, 1421, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1300, 1215, 21818, 5457, 48081, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1421, 1215, 4301, 5457, 48081, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13, 7675, 1975, 11, 1186, 1640, 288, 6, 1403, 4, 6460, 1215, 30695, 1215, 119, 37379, 1215, 43457, 43048, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1421, 1215, 119, 37379, 5457, 1648, 352, 41615, 4903, 1538, 448, 24667, 1640, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 119, 37379, 10975, 288, 46386, 718, 1975, 8174, 4691, 1215, 16266, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 119, 37379, 10975, 288, 46386, 718, 1975, 8174, 9413, 1215, 36097, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 119, 37379, 10975, 288, 46386, 718, 1975, 8174, 23462, 710, 1215, 18711, 4, 90, 1168, 661, 49338, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 16, 48768, 1640, 13367, 4, 1899, 40899, 6, 14219, 597, 8839, 20981, 40899, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 14219, 7684, 1380, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1300, 5457, 475, 37001, 14721, 26028, 597, 8839, 7061, 1640, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 808, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1403, 4, 13650, 6, 50118, 1437, 1437, 1437, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Example 4: {'repository_name': 'NICTA/revrand', 'func_path_in_repository': 'revrand/utils/decorators.py', 'func_name': 'unvectorize_args', 'whole_func_string': 'def unvectorize_args(fn):\\n\\n    \"\"\"\\n    See Also\\n    --------\\n    revrand.utils.decorators.vectorize_args\\n\\n    Examples\\n    --------\\n    The Rosenbrock function is commonly used as a performance test \\n    problem for optimization algorithms. It and its derivatives are \\n    included in `scipy.optimize` and is implemented as expected by the \\n    family of optimization methods in `scipy.optimize`.\\n\\n        def rosen(x):\\n            return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\\n\\n    This representation makes it unwieldy to perform operations such as \\n    plotting since it is less straightforward to evaluate the function \\n    on a `meshgrid`. This decorator helps reconcile the differences \\n    between these representations.\\n\\n    >>> from scipy.optimize import rosen\\n\\n    >>> rosen(np.array([0.5, 1.5]))\\n    156.5\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5) \\n    ... # doctest: +NORMALIZE_WHITESPACE\\n    156.5    \\n\\n    The `rosen` function is implemented in such a way that it \\n    generalizes to the Rosenbrock function of any number of variables. \\n    This decorator supports can support any functions defined in a \\n    similar manner.\\n\\n    The function with any number of arguments are well-defined:\\n\\n    >>> rosen(np.array([0.5, 1.5, 1., 0., 0.2]))\\n    418.0\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5, 1., 0., 0.2)\\n    ... # can accept any variable number of arguments!\\n    418.0\\n\\n    Make it easier to work with for other operations\\n\\n    >>> rosen_ = unvectorize_args(rosen)\\n    >>> y, x = np.mgrid[0:2.1:0.05, -1:1.2:0.05]\\n    >>> z = rosen_(x, y)\\n    >>> z.round(2)\\n    array([[ 104.  ,   85.25,   69.22, ...,  121.55,  146.42,  174.92],\\n           [  94.25,   76.48,   61.37, ...,  110.78,  134.57,  161.95],\\n           [  85.  ,   68.2 ,   54.02, ...,  100.5 ,  123.22,  149.47],\\n           ..., \\n           [  94.25,  113.53,  133.57, ...,   71.83,   54.77,   39.4 ],\\n           [ 104.  ,  124.25,  145.22, ...,   80.55,   62.42,   45.92],\\n           [ 114.25,  135.48,  157.37, ...,   89.78,   70.57,   52.95]])\\n\\n    Now this can be directly plotted with `mpl_toolkits.mplot3d.Axes3D` \\n    and `ax.plot_surface`.\\n\\n    \"\"\"\\n    @wraps(fn)\\n    def new_fn(*args):\\n        return fn(np.asarray(args))\\n    return new_fn', 'language': 'python', 'func_code_string': 'def unvectorize_args(fn):\\n\\n    \"\"\"\\n    See Also\\n    --------\\n    revrand.utils.decorators.vectorize_args\\n\\n    Examples\\n    --------\\n    The Rosenbrock function is commonly used as a performance test \\n    problem for optimization algorithms. It and its derivatives are \\n    included in `scipy.optimize` and is implemented as expected by the \\n    family of optimization methods in `scipy.optimize`.\\n\\n        def rosen(x):\\n            return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\\n\\n    This representation makes it unwieldy to perform operations such as \\n    plotting since it is less straightforward to evaluate the function \\n    on a `meshgrid`. This decorator helps reconcile the differences \\n    between these representations.\\n\\n    >>> from scipy.optimize import rosen\\n\\n    >>> rosen(np.array([0.5, 1.5]))\\n    156.5\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5) \\n    ... # doctest: +NORMALIZE_WHITESPACE\\n    156.5    \\n\\n    The `rosen` function is implemented in such a way that it \\n    generalizes to the Rosenbrock function of any number of variables. \\n    This decorator supports can support any functions defined in a \\n    similar manner.\\n\\n    The function with any number of arguments are well-defined:\\n\\n    >>> rosen(np.array([0.5, 1.5, 1., 0., 0.2]))\\n    418.0\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5, 1., 0., 0.2)\\n    ... # can accept any variable number of arguments!\\n    418.0\\n\\n    Make it easier to work with for other operations\\n\\n    >>> rosen_ = unvectorize_args(rosen)\\n    >>> y, x = np.mgrid[0:2.1:0.05, -1:1.2:0.05]\\n    >>> z = rosen_(x, y)\\n    >>> z.round(2)\\n    array([[ 104.  ,   85.25,   69.22, ...,  121.55,  146.42,  174.92],\\n           [  94.25,   76.48,   61.37, ...,  110.78,  134.57,  161.95],\\n           [  85.  ,   68.2 ,   54.02, ...,  100.5 ,  123.22,  149.47],\\n           ..., \\n           [  94.25,  113.53,  133.57, ...,   71.83,   54.77,   39.4 ],\\n           [ 104.  ,  124.25,  145.22, ...,   80.55,   62.42,   45.92],\\n           [ 114.25,  135.48,  157.37, ...,   89.78,   70.57,   52.95]])\\n\\n    Now this can be directly plotted with `mpl_toolkits.mplot3d.Axes3D` \\n    and `ax.plot_surface`.\\n\\n    \"\"\"\\n    @wraps(fn)\\n    def new_fn(*args):\\n        return fn(np.asarray(args))\\n    return new_fn', 'func_code_tokens': ['def', 'unvectorize_args', '(', 'fn', ')', ':', '@', 'wraps', '(', 'fn', ')', 'def', 'new_fn', '(', '*', 'args', ')', ':', 'return', 'fn', '(', 'np', '.', 'asarray', '(', 'args', ')', ')', 'return', 'new_fn'], 'func_documentation_string': 'See Also\\n    --------\\n    revrand.utils.decorators.vectorize_args\\n\\n    Examples\\n    --------\\n    The Rosenbrock function is commonly used as a performance test \\n    problem for optimization algorithms. It and its derivatives are \\n    included in `scipy.optimize` and is implemented as expected by the \\n    family of optimization methods in `scipy.optimize`.\\n\\n        def rosen(x):\\n            return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\\n\\n    This representation makes it unwieldy to perform operations such as \\n    plotting since it is less straightforward to evaluate the function \\n    on a `meshgrid`. This decorator helps reconcile the differences \\n    between these representations.\\n\\n    >>> from scipy.optimize import rosen\\n\\n    >>> rosen(np.array([0.5, 1.5]))\\n    156.5\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5) \\n    ... # doctest: +NORMALIZE_WHITESPACE\\n    156.5    \\n\\n    The `rosen` function is implemented in such a way that it \\n    generalizes to the Rosenbrock function of any number of variables. \\n    This decorator supports can support any functions defined in a \\n    similar manner.\\n\\n    The function with any number of arguments are well-defined:\\n\\n    >>> rosen(np.array([0.5, 1.5, 1., 0., 0.2]))\\n    418.0\\n\\n    >>> unvectorize_args(rosen)(0.5, 1.5, 1., 0., 0.2)\\n    ... # can accept any variable number of arguments!\\n    418.0\\n\\n    Make it easier to work with for other operations\\n\\n    >>> rosen_ = unvectorize_args(rosen)\\n    >>> y, x = np.mgrid[0:2.1:0.05, -1:1.2:0.05]\\n    >>> z = rosen_(x, y)\\n    >>> z.round(2)\\n    array([[ 104.  ,   85.25,   69.22, ...,  121.55,  146.42,  174.92],\\n           [  94.25,   76.48,   61.37, ...,  110.78,  134.57,  161.95],\\n           [  85.  ,   68.2 ,   54.02, ...,  100.5 ,  123.22,  149.47],\\n           ..., \\n           [  94.25,  113.53,  133.57, ...,   71.83,   54.77,   39.4 ],\\n           [ 104.  ,  124.25,  145.22, ...,   80.55,   62.42,   45.92],\\n           [ 114.25,  135.48,  157.37, ...,   89.78,   70.57,   52.95]])\\n\\n    Now this can be directly plotted with `mpl_toolkits.mplot3d.Axes3D` \\n    and `ax.plot_surface`.', 'func_documentation_tokens': ['See', 'Also', '--------', 'revrand', '.', 'utils', '.', 'decorators', '.', 'vectorize_args'], 'split_name': 'train', 'func_code_url': 'https://github.com/NICTA/revrand/blob/4c1881b6c1772d2b988518e49dde954f165acfb6/revrand/utils/decorators.py#L204-L270', 'input_ids': [0, 9232, 36685, 24427, 2072, 1215, 48204, 1640, 42441, 3256, 50140, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 4250, 1578, 50118, 1437, 1437, 1437, 45177, 50118, 1437, 1437, 1437, 6910, 22103, 4, 49320, 4, 11127, 368, 3629, 4, 48219, 2072, 1215, 48204, 50140, 1437, 1437, 1437, 34284, 50118, 1437, 1437, 1437, 45177, 50118, 1437, 1437, 1437, 20, 11998, 7450, 2420, 5043, 16, 10266, 341, 25, 10, 819, 1296, 1437, 50118, 1437, 1437, 1437, 936, 13, 25212, 16964, 4, 85, 8, 63, 19069, 32, 1437, 50118, 1437, 1437, 1437, 1165, 11, 22209, 3866, 1588, 219, 4, 35692, 2072, 12905, 8, 16, 6264, 25, 421, 30, 5, 1437, 50118, 1437, 1437, 1437, 284, 9, 25212, 6448, 11, 22209, 3866, 1588, 219, 4, 35692, 2072, 49024, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 3816, 4533, 7305, 1640, 1178, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 6797, 1640, 1866, 4, 288, 3226, 1640, 1178, 10975, 134, 35, 48520, 1178, 10975, 36185, 134, 742, 12606, 176, 4, 288, 43, 12606, 176, 4, 288, 2055, 36, 134, 12, 1178, 10975, 36185, 134, 45587, 12606, 176, 4, 288, 43, 50140, 1437, 1437, 1437, 152, 8985, 817, 24, 10963, 8363, 219, 7, 3008, 1414, 215, 25, 1437, 50118, 1437, 1437, 1437, 22849, 187, 24, 16, 540, 15196, 7, 10516, 5, 5043, 1437, 50118, 1437, 1437, 1437, 15, 10, 22209, 119, 4891, 25685, 49024, 152, 12489, 2630, 2607, 27389, 5, 5550, 1437, 50118, 1437, 1437, 1437, 227, 209, 30464, 4, 50140, 1437, 1437, 1437, 39365, 31, 2850, 1588, 219, 4, 35692, 2072, 6595, 4533, 7305, 50140, 1437, 1437, 1437, 39365, 4533, 7305, 1640, 44976, 4, 30766, 48443, 288, 4, 245, 6, 112, 4, 245, 742, 35122, 50118, 1437, 1437, 1437, 25664, 4, 245, 50140, 1437, 1437, 1437, 39365, 36685, 24427, 2072, 1215, 48204, 1640, 3985, 225, 21704, 288, 4, 245, 6, 112, 4, 245, 43, 1437, 50118, 1437, 1437, 1437, 1666, 849, 40975, 990, 35, 2055, 25565, 43602, 41697, 1215, 26369, 2068, 1723, 510, 15949, 50118, 1437, 1437, 1437, 25664, 4, 245, 1437, 1437, 1437, 1437, 50140, 1437, 1437, 1437, 20, 22209, 3985, 225, 12905, 5043, 16, 6264, 11, 215, 10, 169, 14, 24, 1437, 50118, 1437, 1437, 1437, 937, 7396, 7, 5, 11998, 7450, 2420, 5043, 9, 143, 346, 9, 25083, 4, 1437, 50118, 1437, 1437, 1437, 152, 12489, 2630, 4548, 64, 323, 143, 8047, 6533, 11, 10, 1437, 50118, 1437, 1437, 1437, 1122, 4737, 4, 50140, 1437, 1437, 1437, 20, 5043, 19, 143, 346, 9, 7576, 32, 157, 12, 30764, 35, 50140, 1437, 1437, 1437, 39365, 4533, 7305, 1640, 44976, 4, 30766, 48443, 288, 4, 245, 6, 112, 4, 245, 6, 112, 482, 321, 482, 321, 4, 176, 742, 35122, 50118, 1437, 1437, 1437, 42928, 4, 288, 50140, 1437, 1437, 1437, 39365, 36685, 24427, 2072, 1215, 48204, 1640, 3985, 225, 21704, 288, 4, 245, 6, 112, 4, 245, 6, 112, 482, 321, 482, 321, 4, 176, 43, 50118, 1437, 1437, 1437, 1666, 849, 64, 3264, 143, 15594, 346, 9, 7576, 328, 50118, 1437, 1437, 1437, 42928, 4, 288, 50140, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Columns in dataset: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'input_ids', 'attention_mask']\n",
      "Columns to use: ['input_ids', 'attention_mask']\n",
      "Example 0: {'repository_name': 'ktbyers/netmiko', 'func_path_in_repository': 'netmiko/ubiquiti/edge_ssh.py', 'func_name': 'UbiquitiEdgeSSH.save_config', 'whole_func_string': 'def save_config(self, cmd=\"write memory\", confirm=False, confirm_response=\"\"):\\n        \"\"\"Saves configuration.\"\"\"\\n        return super(UbiquitiEdgeSSH, self).save_config(\\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\\n        )', 'language': 'python', 'func_code_string': 'def save_config(self, cmd=\"write memory\", confirm=False, confirm_response=\"\"):\\n        \"\"\"Saves configuration.\"\"\"\\n        return super(UbiquitiEdgeSSH, self).save_config(\\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\\n        )', 'func_code_tokens': ['def', 'save_config', '(', 'self', ',', 'cmd', '=', '\"write memory\"', ',', 'confirm', '=', 'False', ',', 'confirm_response', '=', '\"\"', ')', ':', 'return', 'super', '(', 'UbiquitiEdgeSSH', ',', 'self', ')', '.', 'save_config', '(', 'cmd', '=', 'cmd', ',', 'confirm', '=', 'confirm', ',', 'confirm_response', '=', 'confirm_response', ')'], 'func_documentation_string': 'Saves configuration.', 'func_documentation_tokens': ['Saves', 'configuration', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/ktbyers/netmiko/blob/54e6116c0b4664de2123081937e0a9a27bdfdfea/netmiko/ubiquiti/edge_ssh.py#L43-L47', 'input_ids': [0, 9232, 1871, 1215, 43163, 1640, 13367, 6, 49099, 40635, 29631, 3783, 1297, 4559, 5214, 46659, 6, 4559, 1215, 41510, 48893, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 104, 9419, 20393, 72, 48149, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 2422, 1640, 44588, 9071, 4933, 37054, 8108, 725, 6, 1403, 322, 31575, 1215, 43163, 1640, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49099, 5214, 48211, 6, 4559, 5214, 17075, 9856, 6, 4559, 1215, 41510, 5214, 17075, 9856, 1215, 41510, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4839, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 1: {'repository_name': 'OpenGov/carpenter', 'func_path_in_repository': 'carpenter/blocks/tableanalyzer.py', 'func_name': 'TableAnalyzer._find_valid_block', 'whole_func_string': \"def _find_valid_block(self, table, worksheet, flags, units, used_cells, start_pos, end_pos):\\n        '''\\n        Searches for the next location where a valid block could reside and constructs the block\\n        object representing that location.\\n        '''\\n        for row_index in range(len(table)):\\n            if row_index < start_pos[0] or row_index > end_pos[0]:\\n                continue\\n            convRow = table[row_index]\\n            used_row = used_cells[row_index]\\n            for column_index, conv in enumerate(convRow):\\n                if (column_index < start_pos[1] or column_index > end_pos[1] or used_row[column_index]):\\n                    continue\\n                # Is non empty cell?\\n                if not is_empty_cell(conv):\\n                    block_start, block_end = self._find_block_bounds(table, used_cells,\\n                            (row_index, column_index), start_pos, end_pos)\\n                    if (block_end[0] > block_start[0] and\\n                        block_end[1] > block_start[1]):\\n                        try:\\n                            return TableBlock(table, used_cells, block_start, block_end, worksheet,\\n                                flags, units, self.assume_complete_blocks, self.max_title_rows)\\n                        except InvalidBlockError:\\n                            pass\\n                        # Prevent infinite loops if something goes wrong\\n                        used_cells[row_index][column_index] = True\", 'language': 'python', 'func_code_string': \"def _find_valid_block(self, table, worksheet, flags, units, used_cells, start_pos, end_pos):\\n        '''\\n        Searches for the next location where a valid block could reside and constructs the block\\n        object representing that location.\\n        '''\\n        for row_index in range(len(table)):\\n            if row_index < start_pos[0] or row_index > end_pos[0]:\\n                continue\\n            convRow = table[row_index]\\n            used_row = used_cells[row_index]\\n            for column_index, conv in enumerate(convRow):\\n                if (column_index < start_pos[1] or column_index > end_pos[1] or used_row[column_index]):\\n                    continue\\n                # Is non empty cell?\\n                if not is_empty_cell(conv):\\n                    block_start, block_end = self._find_block_bounds(table, used_cells,\\n                            (row_index, column_index), start_pos, end_pos)\\n                    if (block_end[0] > block_start[0] and\\n                        block_end[1] > block_start[1]):\\n                        try:\\n                            return TableBlock(table, used_cells, block_start, block_end, worksheet,\\n                                flags, units, self.assume_complete_blocks, self.max_title_rows)\\n                        except InvalidBlockError:\\n                            pass\\n                        # Prevent infinite loops if something goes wrong\\n                        used_cells[row_index][column_index] = True\", 'func_code_tokens': ['def', '_find_valid_block', '(', 'self', ',', 'table', ',', 'worksheet', ',', 'flags', ',', 'units', ',', 'used_cells', ',', 'start_pos', ',', 'end_pos', ')', ':', 'for', 'row_index', 'in', 'range', '(', 'len', '(', 'table', ')', ')', ':', 'if', 'row_index', '<', 'start_pos', '[', '0', ']', 'or', 'row_index', '>', 'end_pos', '[', '0', ']', ':', 'continue', 'convRow', '=', 'table', '[', 'row_index', ']', 'used_row', '=', 'used_cells', '[', 'row_index', ']', 'for', 'column_index', ',', 'conv', 'in', 'enumerate', '(', 'convRow', ')', ':', 'if', '(', 'column_index', '<', 'start_pos', '[', '1', ']', 'or', 'column_index', '>', 'end_pos', '[', '1', ']', 'or', 'used_row', '[', 'column_index', ']', ')', ':', 'continue', '# Is non empty cell?', 'if', 'not', 'is_empty_cell', '(', 'conv', ')', ':', 'block_start', ',', 'block_end', '=', 'self', '.', '_find_block_bounds', '(', 'table', ',', 'used_cells', ',', '(', 'row_index', ',', 'column_index', ')', ',', 'start_pos', ',', 'end_pos', ')', 'if', '(', 'block_end', '[', '0', ']', '>', 'block_start', '[', '0', ']', 'and', 'block_end', '[', '1', ']', '>', 'block_start', '[', '1', ']', ')', ':', 'try', ':', 'return', 'TableBlock', '(', 'table', ',', 'used_cells', ',', 'block_start', ',', 'block_end', ',', 'worksheet', ',', 'flags', ',', 'units', ',', 'self', '.', 'assume_complete_blocks', ',', 'self', '.', 'max_title_rows', ')', 'except', 'InvalidBlockError', ':', 'pass', '# Prevent infinite loops if something goes wrong', 'used_cells', '[', 'row_index', ']', '[', 'column_index', ']', '=', 'True'], 'func_documentation_string': 'Searches for the next location where a valid block could reside and constructs the block\\n        object representing that location.', 'func_documentation_tokens': ['Searches', 'for', 'the', 'next', 'location', 'where', 'a', 'valid', 'block', 'could', 'reside', 'and', 'constructs', 'the', 'block', 'object', 'representing', 'that', 'location', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/OpenGov/carpenter/blob/0ab3c54c05133b9b0468c63e834a7ce3a6fb575b/carpenter/blocks/tableanalyzer.py#L198-L223', 'input_ids': [0, 9232, 18134, 26559, 1215, 42679, 1215, 16776, 1640, 13367, 6, 2103, 6, 1364, 25148, 6, 9287, 6, 2833, 6, 341, 1215, 40936, 6, 386, 1215, 11474, 6, 253, 1215, 11474, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 33454, 5559, 13, 5, 220, 2259, 147, 10, 8218, 1803, 115, 23773, 8, 43978, 5, 1803, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 7626, 4561, 14, 2259, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 128, 17809, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13, 3236, 1215, 18480, 11, 1186, 1640, 8476, 1640, 14595, 43, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 3236, 1215, 18480, 28696, 386, 1215, 11474, 10975, 288, 742, 50, 3236, 1215, 18480, 8061, 253, 1215, 11474, 10975, 288, 42645, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 535, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 15380, 43277, 5457, 2103, 10975, 4610, 1215, 18480, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 341, 1215, 4610, 5457, 341, 1215, 40936, 10975, 4610, 1215, 18480, 742, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13, 6730, 1215, 18480, 6, 15380, 11, 41949, 877, 1640, 40474, 43277, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 36, 42351, 1215, 18480, 28696, 386, 1215, 11474, 10975, 134, 742, 50, 6730, 1215, 18480, 8061, 253, 1215, 11474, 10975, 134, 742, 50, 341, 1215, 4610, 10975, 42351, 1215, 18480, 742, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 535, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 1534, 786, 5802, 3551, 116, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 45, 16, 1215, 41486, 1215, 7841, 1640, 40474, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1803, 1215, 13124, 6, 1803, 1215, 1397, 5457, 1403, 48030, 26559, 1215, 16776, 1215, 428, 12363, 1640, 14595, 6, 341, 1215, 40936, 6, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 36, 4610, 1215, 18480, 6, 6730, 1215, 18480, 238, 386, 1215, 11474, 6, 253, 1215, 11474, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 36, 16776, 1215, 1397, 10975, 288, 742, 8061, 1803, 1215, 13124, 10975, 288, 742, 8, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1803, 1215, 1397, 10975, 134, 742, 8061, 1803, 1215, 13124, 10975, 134, 742, 3256, 50118, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Example 2: {'repository_name': 'BoGoEngine/bogo-python', 'func_path_in_repository': 'bogo/accent.py', 'func_name': 'add_accent_char', 'whole_func_string': 'def add_accent_char(char, accent):\\n    \"\"\"\\n    Add accent to a single char.  Parameter accent is member of class\\n    Accent\\n    \"\"\"\\n    if char == \"\":\\n        return \"\"\\n    case = char.isupper()\\n    char = char.lower()\\n    index = utils.VOWELS.find(char)\\n    if (index != -1):\\n        index = index - index % 6 + 5\\n        char = utils.VOWELS[index - accent]\\n    return utils.change_case(char, case)', 'language': 'python', 'func_code_string': 'def add_accent_char(char, accent):\\n    \"\"\"\\n    Add accent to a single char.  Parameter accent is member of class\\n    Accent\\n    \"\"\"\\n    if char == \"\":\\n        return \"\"\\n    case = char.isupper()\\n    char = char.lower()\\n    index = utils.VOWELS.find(char)\\n    if (index != -1):\\n        index = index - index % 6 + 5\\n        char = utils.VOWELS[index - accent]\\n    return utils.change_case(char, case)', 'func_code_tokens': ['def', 'add_accent_char', '(', 'char', ',', 'accent', ')', ':', 'if', 'char', '==', '\"\"', ':', 'return', '\"\"', 'case', '=', 'char', '.', 'isupper', '(', ')', 'char', '=', 'char', '.', 'lower', '(', ')', 'index', '=', 'utils', '.', 'VOWELS', '.', 'find', '(', 'char', ')', 'if', '(', 'index', '!=', '-', '1', ')', ':', 'index', '=', 'index', '-', 'index', '%', '6', '+', '5', 'char', '=', 'utils', '.', 'VOWELS', '[', 'index', '-', 'accent', ']', 'return', 'utils', '.', 'change_case', '(', 'char', ',', 'case', ')'], 'func_documentation_string': 'Add accent to a single char.  Parameter accent is member of class\\n    Accent', 'func_documentation_tokens': ['Add', 'accent', 'to', 'a', 'single', 'char', '.', 'Parameter', 'accent', 'is', 'member', 'of', 'class', 'Accent'], 'split_name': 'train', 'func_code_url': 'https://github.com/BoGoEngine/bogo-python/blob/9b85329a408ded4cead3539cecba12984d5d7650/bogo/accent.py#L92-L105', 'input_ids': [0, 9232, 1606, 1215, 1043, 6342, 1215, 24262, 1640, 24262, 6, 15056, 3256, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 4287, 15056, 7, 10, 881, 16224, 4, 1437, 34559, 5906, 15056, 16, 919, 9, 1380, 50118, 1437, 1437, 1437, 5438, 1342, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 114, 16224, 45994, 22, 7862, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 41039, 50118, 1437, 1437, 1437, 403, 5457, 16224, 4, 354, 34849, 43048, 50118, 1437, 1437, 1437, 16224, 5457, 16224, 4, 29668, 43048, 50118, 1437, 1437, 1437, 1965, 5457, 16080, 5290, 4, 846, 4581, 16416, 4, 26559, 1640, 24262, 43, 50118, 1437, 1437, 1437, 114, 36, 18480, 49333, 111, 134, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1965, 5457, 1965, 111, 1965, 7606, 231, 2055, 195, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 16224, 5457, 16080, 5290, 4, 846, 4581, 16416, 10975, 18480, 111, 15056, 742, 50118, 1437, 1437, 1437, 671, 16080, 5290, 4, 14035, 1215, 11173, 1640, 24262, 6, 403, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 3: {'repository_name': 'edx/opaque-keys', 'func_path_in_repository': 'opaque_keys/edx/locations.py', 'func_name': 'SlashSeparatedCourseKey.replace', 'whole_func_string': 'def replace(self, **kwargs):\\n        \"\"\"\\n        Return: a new :class:`SlashSeparatedCourseKey` with specific ``kwargs`` replacing\\n            their corresponding values.\\n\\n        Using CourseLocator\\'s replace function results in a mismatch of __init__ args and kwargs.\\n            Replace tries to instantiate a SlashSeparatedCourseKey object with CourseLocator args and kwargs.\\n        \"\"\"\\n        # Deprecation value is hard coded as True in __init__ and therefore does not need to be passed through.\\n        return SlashSeparatedCourseKey(\\n            kwargs.pop(\\'org\\', self.org),\\n            kwargs.pop(\\'course\\', self.course),\\n            kwargs.pop(\\'run\\', self.run),\\n            **kwargs\\n        )', 'language': 'python', 'func_code_string': 'def replace(self, **kwargs):\\n        \"\"\"\\n        Return: a new :class:`SlashSeparatedCourseKey` with specific ``kwargs`` replacing\\n            their corresponding values.\\n\\n        Using CourseLocator\\'s replace function results in a mismatch of __init__ args and kwargs.\\n            Replace tries to instantiate a SlashSeparatedCourseKey object with CourseLocator args and kwargs.\\n        \"\"\"\\n        # Deprecation value is hard coded as True in __init__ and therefore does not need to be passed through.\\n        return SlashSeparatedCourseKey(\\n            kwargs.pop(\\'org\\', self.org),\\n            kwargs.pop(\\'course\\', self.course),\\n            kwargs.pop(\\'run\\', self.run),\\n            **kwargs\\n        )', 'func_code_tokens': ['def', 'replace', '(', 'self', ',', '*', '*', 'kwargs', ')', ':', '# Deprecation value is hard coded as True in __init__ and therefore does not need to be passed through.', 'return', 'SlashSeparatedCourseKey', '(', 'kwargs', '.', 'pop', '(', \"'org'\", ',', 'self', '.', 'org', ')', ',', 'kwargs', '.', 'pop', '(', \"'course'\", ',', 'self', '.', 'course', ')', ',', 'kwargs', '.', 'pop', '(', \"'run'\", ',', 'self', '.', 'run', ')', ',', '*', '*', 'kwargs', ')'], 'func_documentation_string': \"Return: a new :class:`SlashSeparatedCourseKey` with specific ``kwargs`` replacing\\n            their corresponding values.\\n\\n        Using CourseLocator's replace function results in a mismatch of __init__ args and kwargs.\\n            Replace tries to instantiate a SlashSeparatedCourseKey object with CourseLocator args and kwargs.\", 'func_documentation_tokens': ['Return', ':', 'a', 'new', ':', 'class', ':', 'SlashSeparatedCourseKey', 'with', 'specific', 'kwargs', 'replacing', 'their', 'corresponding', 'values', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/edx/opaque-keys/blob/9807168660c12e0551c8fdd58fd1bc6b0bcb0a54/opaque_keys/edx/locations.py#L61-L75', 'input_ids': [0, 9232, 3190, 1640, 13367, 6, 13540, 33294, 48204, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 11968, 35, 10, 92, 4832, 4684, 35, 12905, 26724, 1671, 37729, 271, 1070, 47719, 28152, 12905, 19, 2167, 45518, 33294, 48204, 49519, 8119, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49, 12337, 3266, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 8630, 15210, 45062, 2630, 18, 3190, 5043, 775, 11, 10, 37109, 9, 27148, 25153, 30529, 49503, 8, 449, 605, 48204, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 42439, 5741, 7, 10062, 10599, 10, 41920, 37729, 271, 1070, 47719, 28152, 7626, 19, 15210, 45062, 2630, 49503, 8, 449, 605, 48204, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 849, 6748, 13139, 1258, 923, 16, 543, 40498, 25, 7447, 11, 27148, 25153, 30529, 8, 3891, 473, 45, 240, 7, 28, 1595, 149, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 41920, 37729, 271, 1070, 47719, 28152, 1640, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 449, 605, 48204, 4, 15076, 45803, 1957, 3934, 1403, 4, 1957, 238, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 449, 605, 48204, 4, 15076, 45803, 21282, 3934, 1403, 4, 21282, 238, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 449, 605, 48204, 4, 15076, 45803, 2962, 3934, 1403, 4, 2962, 238, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 13540, 33294, 48204, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 4839, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 4: {'repository_name': 'rigetti/pyquil', 'func_path_in_repository': 'pyquil/api/_base_connection.py', 'func_name': 'ForestConnection._quilc_compile', 'whole_func_string': 'def _quilc_compile(self, quil_program, isa, specs):\\n        \"\"\"\\n        Sends a quilc job to Forest.\\n\\n        Users should use :py:func:`LocalCompiler.quil_to_native_quil` instead of calling this\\n        directly.\\n        \"\"\"\\n        payload = quilc_compile_payload(quil_program, isa, specs)\\n        response = post_json(self.session, self.sync_endpoint + \"/\", payload)\\n        unpacked_response = response.json()\\n        return unpacked_response', 'language': 'python', 'func_code_string': 'def _quilc_compile(self, quil_program, isa, specs):\\n        \"\"\"\\n        Sends a quilc job to Forest.\\n\\n        Users should use :py:func:`LocalCompiler.quil_to_native_quil` instead of calling this\\n        directly.\\n        \"\"\"\\n        payload = quilc_compile_payload(quil_program, isa, specs)\\n        response = post_json(self.session, self.sync_endpoint + \"/\", payload)\\n        unpacked_response = response.json()\\n        return unpacked_response', 'func_code_tokens': ['def', '_quilc_compile', '(', 'self', ',', 'quil_program', ',', 'isa', ',', 'specs', ')', ':', 'payload', '=', 'quilc_compile_payload', '(', 'quil_program', ',', 'isa', ',', 'specs', ')', 'response', '=', 'post_json', '(', 'self', '.', 'session', ',', 'self', '.', 'sync_endpoint', '+', '\"/\"', ',', 'payload', ')', 'unpacked_response', '=', 'response', '.', 'json', '(', ')', 'return', 'unpacked_response'], 'func_documentation_string': 'Sends a quilc job to Forest.\\n\\n        Users should use :py:func:`LocalCompiler.quil_to_native_quil` instead of calling this\\n        directly.', 'func_documentation_tokens': ['Sends', 'a', 'quilc', 'job', 'to', 'Forest', '.'], 'split_name': 'train', 'func_code_url': 'https://github.com/rigetti/pyquil/blob/ec98e453084b0037d69d8c3245f6822a5422593d/pyquil/api/_base_connection.py#L386-L396', 'input_ids': [0, 9232, 18134, 2253, 718, 438, 1215, 11828, 1848, 1640, 13367, 6, 2677, 718, 1215, 28644, 6, 16, 102, 6, 21634, 3256, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 208, 8845, 10, 2677, 718, 438, 633, 7, 5761, 4, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 16034, 197, 304, 4832, 17163, 35, 48901, 35, 12905, 24476, 24699, 10329, 4, 2253, 718, 1215, 560, 1215, 34551, 1215, 2253, 718, 12905, 1386, 9, 1765, 42, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2024, 4, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 29239, 5457, 2677, 718, 438, 1215, 11828, 1848, 1215, 14066, 16204, 1640, 2253, 718, 1215, 28644, 6, 16, 102, 6, 21634, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1263, 5457, 618, 1215, 40962, 1640, 13367, 4, 39035, 6, 1403, 4, 45176, 1215, 1397, 2300, 2055, 48789, 1297, 29239, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 23089, 10074, 1215, 41510, 5457, 1263, 4, 40962, 43048, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 23089, 10074, 1215, 41510, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "python_train_tf= to_tf(python_train_tok)\n",
    "python_valid_tf= to_tf(python_valid_tok)\n",
    "python_test_tf= to_tf(python_test_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the actual fine-tuning of the Roberta model is here\n",
    "model = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
